{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Step-by-step\n",
    "\n",
    "Pieter Overdevest  \n",
    "2024-02-09\n",
    "\n",
    "For suggestions/questions regarding this notebook, please contact\n",
    "[Pieter Overdevest](https://www.linkedin.com/in/pieteroverdevest/)\n",
    "(pieter@innovatewithdata.nl).\n",
    "\n",
    "### How to work with this Jupyter Notebook yourself?\n",
    "\n",
    "- Get a copy of the repository [machine-learning-with-python-explainers](https://github.com/EAISI/machine-learning-with-python-explainers) on EAISI's GitHub site. This can be done by either cloning the repo or simply downloading the zip-file. Both options are explained in this Youtube video by [Coderama](https://www.youtube.com/watch?v=EhxPBMQFCaI). Note, the term 'repository' is often abbreviated as 'repo'.\n",
    "\n",
    "- Copy the Jupyter Notebook 'ames-housing-pieter.ipynb' and the 'utils_pieter' folder to your own project folder.\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This case is inspired by Kaggle’s [Getting Started Prediction Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). The information you need in order to work on this case can be found in the repo\n",
    "[‘discover-projects/ames-housing’](https://github.com/EAISI/discover-projects/tree/main/ames-housing) on EAISI's GitHub site.\n",
    "The questions - and therefore this notebook - are structured according to the CRISP-DM framework.\n",
    "\n",
    "When referring to,\n",
    "\n",
    "-   'Python Explainer', see the folder 'python-explainers\\\\'\n",
    "\n",
    "-   'ML Explainer', see the folder 'ml-explainers\\\\'\n",
    "\n",
    "in the repo you just copied.\n",
    "\n",
    "\n",
    "### Import packages\n",
    "A package is simply a folder containing modules and a '\\_\\_init\\_\\_.py' file, also referred to as a 'dunder init' file ('dunder' referring to *d*ouble *under*scores). A module is just a Python file (*.py) holding functions and variables. The dunder init file is what makes the folder callable as a package. You can include Python code in the dunder init file that will be run when the package is imported. We can import complete packages or only specific functions from a package. In the first case we start with 'import' and in the second case we start with 'from'.\n",
    "\n",
    "As part of a solution to an exercise, we may need to import specific third party package. These packages will be imported with the solutions. Of some packages we tend to use many functions. In those cases, we simply load the whole package. Typically, we do this under an alias to make it simpler to refer to a function in the concerned package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages and assign to a shorter alias.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load packages without an alias, since the package name is already small.\n",
    "import math\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over time, I have developed a package containing a number of generally applicable functions. I have named this package 'utils_pieter'. I have included this package in the repo you just copied. If you place the 'utils_pieter/' folder in the same project folder where you copied this Jupyter Notebook 'ames-housing-pieter.ipynb' to, you can import the package by simply stating \"import utils_pieter as up\". This means we can simply refer to \"up\" in case we want to use a function in this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Import package.\n",
    "import utils_pieter as up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to use a function without having to refer to the package each time, you can import it directly from the package. Here, we import the `info()` function, as example, and because we use it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function.\n",
    "from utils_pieter import f_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using scikit-learn version 1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Note, '%matplotlib inline' ensures matplotlib graphs will be included in your notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting Pandas options.\n",
    "pd.set_option(\"display.max_rows\", 30) # How to display all rows from data frame using pandas. Setting value to None to show all rows.\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_info_columns\", 100)\n",
    "pd.set_option(\"display.max_info_rows\", 1000000)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "#pd.set_option(\"styler.format.precision\", 2)\n",
    "\n",
    "# Setting Matplotlib font sizes.\n",
    "FONT_SMALL  = 8\n",
    "FONT_MEDIUM = 16\n",
    "FONT_LARGE  = 20\n",
    "\n",
    "plt.rc('axes',   titlesize      = FONT_LARGE)   # axes title\n",
    "plt.rc('axes',   labelsize      = FONT_MEDIUM)  # axes x and y labels\n",
    "plt.rc('xtick',  labelsize      = FONT_MEDIUM)  # x tick labels\n",
    "plt.rc('ytick',  labelsize      = FONT_MEDIUM)  # y tick labels\n",
    "plt.rc('legend', fontsize       = FONT_MEDIUM)  # legend items\n",
    "plt.rc('legend', title_fontsize = FONT_LARGE)   # legend title\n",
    "plt.rc('figure', titlesize      = FONT_LARGE)   # figure title\n",
    "plt.rc('font',   size           = FONT_SMALL)   # other texts\n",
    "plt.rc('figure', figsize        = (20, 10))     # figure size. This replaces 'plt.figure(figsize=(20,10))' in every cell.\n",
    "\n",
    "# Setting sklearn parameter for Pipeline visualization.\n",
    "# see https://towardsdatascience.com/are-you-using-pipeline-in-scikit-learn-ac4cd85cb27f\n",
    "sklearn.set_config(display=\"diagram\")\n",
    "\n",
    "# Confirm sklearn version.\n",
    "print(f\"using scikit-learn version {sklearn.__version__}\")\n",
    "\n",
    "# Seaborn theme.\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business context**: Real estate agency 'Homely Homes' incorporated in Ames, Iowa (USA), needs a good first impression of the sale price of a house as soon as it comes on the market, without having to visit the house. Today, 'Homely Homes' uses their team of real estate agents of different levels of expertise to get an estimate based on the information that is available online. The quality of the estimates differs highly depending on who is asked. And, not surprisingly, the experienced agents are not always readily available. So, the management team of Homely Homes has decided to go full on data, and is requesting you to develop a model that can predict the sale price by the push of a button.\n",
    "\n",
    "**Business objective**: To become independent on real estate agents to estimate sale prices.\n",
    "\n",
    "**Scope**: All homes in the city of Ames, IA (USA).\n",
    "\n",
    "**Project goal**: Develop a model that predicts sale price of a house given a set of it's variables,\n",
    "\n",
    "- The performance metric for your prediction model is the Root Mean Squared Logarithmic Error (RMSLE), i.e., the root mean squared error between the logarithm of the predicted value and the logarithm of the observed sale price. Taking the logarithm means that errors in predicting very expensive houses and cheaper houses will affect the result equally.\n",
    "\n",
    "- Looking at the [public leaderboard](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/leaderboard), the top 2% have an RMSLE of 0.00044, whilst 25th-percentile and the median performance is at 0.125 and 0.14, respectively.\n",
    "\n",
    "- As an extra challenge, you can try to trade-off the number of predictors (less is better) vs. performance. Can you make the top 10% (RMSLE 0.123) with the least number of predictors?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Load the 'Ames Housing' dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more than one way to load the 'Ames Housing' dataset. The first two options below load the data directly from a Github repo. The third option can be used in case the data is stored locally."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Read the data straight from GitHub (A)**\n",
    "\n",
    "a. Go to the repo [‘discover-projects/ames-housing’](https://github.com/EAISI/discover-projects/tree/main/ames-housing) on EAISI's GitHub site;\n",
    "\n",
    "b. Click on the 'AmesHousing.csv' file;\n",
    "\n",
    "c. Click on the **Raw** button;\n",
    "\n",
    "d. Copy the URL in the URL bar;\n",
    "\n",
    "e. Paste the URL in the Pandas function `read_csv()`, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig1 = pd.read_csv(\n",
    "    \n",
    "    \"https://raw.githubusercontent.com/EAISI/discover-projects/main/ames-housing/AmesHousing.csv\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 - Read the data straight from GitHub (B)**\n",
    "\n",
    "a. Go to the repo [‘discover-projects/ames-housing’](https://github.com/EAISI/discover-projects/tree/main/ames-housing) on EAISI's GitHub site;\n",
    "\n",
    "b. Right click (Win) of control click (Mac OSX) on the 'AmesHousing.csv' file;\n",
    "\n",
    "c. Select 'Copy link';\n",
    "\n",
    "d. Paste the URL in the Pandas function `read_csv()`;\n",
    "\n",
    "e. Append '?raw=True' to the URL, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_orig2 = pd.read_csv(  \n",
    "\n",
    "#     \"https://github.com/EAISI/discover-projects/blob/main/ames-housing/AmesHousing.csv?raw=True\",\n",
    "\n",
    "#     # Just to demonstrate another variable of the `read_csv()` function. In case you want to enforce a\n",
    "#     # certain data type on a particular column, you can assign a dictionary to the `dtype` argument.\n",
    "#     # Though, down below we set the types in a different manner.\n",
    "#     dtype = {\n",
    "#         'Neighborhood':'category'        \n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 - Read the data from a local file**\n",
    "\n",
    "The same Pandas function `read_csv()` can be used to read a CSV from your local computer. Note, `f\"some text {variable} text continues.\"` is called an f-string, and allows you to insert variables inside a string. In case you are not familiar with f-strings, see \"[Python's F-String for String Interpolation and Formatting](https://realpython.com/python-f-strings/)\" on realpython.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load local data.\n",
    "# df_orig3 = pd.read_csv(\n",
    "    \n",
    "#     f\"/Users/{up.f_get_account_name()}/Innovate with Data Dropbox/Innovate With Data/Partners/\"\n",
    "#     'PE/2024 02 - EAISI - Discover Projects/ames-housing/AmesHousing.csv'\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will make modifications to the data, it is good practice to make a copy, so we can always look back and compare what was in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig1.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Descriptive statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding (continued)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore the data as received:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Which variables are numerical? And which are categorical? How many variables do we have of both types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Order', 'PID', 'MS SubClass', 'Lot Frontage', 'Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd', 'Fireplaces', 'Garage Yr Blt', 'Garage Cars', 'Garage Area', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Misc Val', 'Mo Sold', 'Yr Sold', 'SalePrice']\n",
      "\n",
      "Number of numerical variables: 39\n"
     ]
    }
   ],
   "source": [
    "df_num_orig    = df_orig.select_dtypes(include='number')\n",
    "l_df_num_names = list(df_num_orig.columns)\n",
    "\n",
    "print(l_df_num_names)\n",
    "print(f\"\\nNumber of numerical variables: {len(l_df_num_names)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, \"\\n\" is a special character that invokes a newline.\n",
    "\n",
    "The `object` type refers to a string type in Pandas (str), so we can perform string operations instead of mathematical ones. You might say, shouldn't we use \"include='category'\"? Try it out, and observe the result. Although, from a data science perspective, text is considered to be of the categorical type, i.e., categorical or factor variables. Python reserves the term \"category\" type for a special type of string folumn, where all unique values in the str column are stored in a separate table and each value in the str column is stored as an integer. This saves memory and speeds up the processing, see also \"Extra - Optimize memory usage\" below.\n",
    "\n",
    "Since this is a technicality in Python, we will still refer to 'categorical variables'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MS Zoning', 'Street', 'Alley', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Exter Qual', 'Exter Cond', 'Foundation', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2', 'Heating', 'Heating QC', 'Central Air', 'Electrical', 'Kitchen Qual', 'Functional', 'Fireplace Qu', 'Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond', 'Paved Drive', 'Pool QC', 'Fence', 'Misc Feature', 'Sale Type', 'Sale Condition']\n",
      "\n",
      "Number of categorical variables: 43\n"
     ]
    }
   ],
   "source": [
    "df_cat_orig    = df_orig.select_dtypes(include='object')\n",
    "l_df_cat_names = list(df_cat_orig.columns)\n",
    "\n",
    "print(l_df_cat_names)\n",
    "print(f\"\\nNumber of categorical variables: {len(l_df_cat_names)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always good to do your book keeping and check your assumptions. Do we have all columns in either df_num_orig and df_cat_orig? Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the original data:                    82\n",
      "Number of columns in df_num_orig and df_cat_orig combined: 82\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Number of columns in the original data:                    \"\n",
    "    f\"{df_orig.shape[1]}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of columns in df_num_orig and df_cat_orig combined: \"\n",
    "    f\"{df_num_orig.shape[1]+df_cat_orig.shape[1]}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. How many missing values do each of the variables have (variable completeness) and what are the variable types? Is `SalePrice` complete? (hint: use `info()`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info()` method shows the variable names and some high level information on each. We observe different data types for integers and floats, i.e., different 'suitcase sizes'. What are the dtypes of each variable? What do we learn from 'Non-Null Count'?\n",
    "\n",
    "Yes, `SalePrice` is complete. The data frame has 2930 rows ('entries') and there are 2930 'Non-null' values present in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 39 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order            2930 non-null   int64  \n",
      " 1   PID              2930 non-null   int64  \n",
      " 2   MS SubClass      2930 non-null   int64  \n",
      " 3   Lot Frontage     2440 non-null   float64\n",
      " 4   Lot Area         2930 non-null   int64  \n",
      " 5   Overall Qual     2930 non-null   int64  \n",
      " 6   Overall Cond     2930 non-null   int64  \n",
      " 7   Year Built       2930 non-null   int64  \n",
      " 8   Year Remod/Add   2930 non-null   int64  \n",
      " 9   Mas Vnr Area     2907 non-null   float64\n",
      " 10  BsmtFin SF 1     2929 non-null   float64\n",
      " 11  BsmtFin SF 2     2929 non-null   float64\n",
      " 12  Bsmt Unf SF      2929 non-null   float64\n",
      " 13  Total Bsmt SF    2929 non-null   float64\n",
      " 14  1st Flr SF       2930 non-null   int64  \n",
      " 15  2nd Flr SF       2930 non-null   int64  \n",
      " 16  Low Qual Fin SF  2930 non-null   int64  \n",
      " 17  Gr Liv Area      2930 non-null   int64  \n",
      " 18  Bsmt Full Bath   2928 non-null   float64\n",
      " 19  Bsmt Half Bath   2928 non-null   float64\n",
      " 20  Full Bath        2930 non-null   int64  \n",
      " 21  Half Bath        2930 non-null   int64  \n",
      " 22  Bedroom AbvGr    2930 non-null   int64  \n",
      " 23  Kitchen AbvGr    2930 non-null   int64  \n",
      " 24  TotRms AbvGrd    2930 non-null   int64  \n",
      " 25  Fireplaces       2930 non-null   int64  \n",
      " 26  Garage Yr Blt    2771 non-null   float64\n",
      " 27  Garage Cars      2929 non-null   float64\n",
      " 28  Garage Area      2929 non-null   float64\n",
      " 29  Wood Deck SF     2930 non-null   int64  \n",
      " 30  Open Porch SF    2930 non-null   int64  \n",
      " 31  Enclosed Porch   2930 non-null   int64  \n",
      " 32  3Ssn Porch       2930 non-null   int64  \n",
      " 33  Screen Porch     2930 non-null   int64  \n",
      " 34  Pool Area        2930 non-null   int64  \n",
      " 35  Misc Val         2930 non-null   int64  \n",
      " 36  Mo Sold          2930 non-null   int64  \n",
      " 37  Yr Sold          2930 non-null   int64  \n",
      " 38  SalePrice        2930 non-null   int64  \n",
      "dtypes: float64(11), int64(28)\n",
      "memory usage: 892.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_num_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 43 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   MS Zoning       2930 non-null   object\n",
      " 1   Street          2930 non-null   object\n",
      " 2   Alley           198 non-null    object\n",
      " 3   Lot Shape       2930 non-null   object\n",
      " 4   Land Contour    2930 non-null   object\n",
      " 5   Utilities       2930 non-null   object\n",
      " 6   Lot Config      2930 non-null   object\n",
      " 7   Land Slope      2930 non-null   object\n",
      " 8   Neighborhood    2930 non-null   object\n",
      " 9   Condition 1     2930 non-null   object\n",
      " 10  Condition 2     2930 non-null   object\n",
      " 11  Bldg Type       2930 non-null   object\n",
      " 12  House Style     2930 non-null   object\n",
      " 13  Roof Style      2930 non-null   object\n",
      " 14  Roof Matl       2930 non-null   object\n",
      " 15  Exterior 1st    2930 non-null   object\n",
      " 16  Exterior 2nd    2930 non-null   object\n",
      " 17  Mas Vnr Type    1155 non-null   object\n",
      " 18  Exter Qual      2930 non-null   object\n",
      " 19  Exter Cond      2930 non-null   object\n",
      " 20  Foundation      2930 non-null   object\n",
      " 21  Bsmt Qual       2850 non-null   object\n",
      " 22  Bsmt Cond       2850 non-null   object\n",
      " 23  Bsmt Exposure   2847 non-null   object\n",
      " 24  BsmtFin Type 1  2850 non-null   object\n",
      " 25  BsmtFin Type 2  2849 non-null   object\n",
      " 26  Heating         2930 non-null   object\n",
      " 27  Heating QC      2930 non-null   object\n",
      " 28  Central Air     2930 non-null   object\n",
      " 29  Electrical      2929 non-null   object\n",
      " 30  Kitchen Qual    2930 non-null   object\n",
      " 31  Functional      2930 non-null   object\n",
      " 32  Fireplace Qu    1508 non-null   object\n",
      " 33  Garage Type     2773 non-null   object\n",
      " 34  Garage Finish   2771 non-null   object\n",
      " 35  Garage Qual     2771 non-null   object\n",
      " 36  Garage Cond     2771 non-null   object\n",
      " 37  Paved Drive     2930 non-null   object\n",
      " 38  Pool QC         13 non-null     object\n",
      " 39  Fence           572 non-null    object\n",
      " 40  Misc Feature    106 non-null    object\n",
      " 41  Sale Type       2930 non-null   object\n",
      " 42  Sale Condition  2930 non-null   object\n",
      "dtypes: object(43)\n",
      "memory usage: 984.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cat_orig.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Create a frequency table counting the number of missing values per variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, using the `info()` method we can get a quick first glance on the variables that have many or no missing values at all. Let's create a simple table listing the variables and their number of missing data, and sort the variables by their 'emptiness' (= 1 - completeness). We conclude that the `Pool QC` variable has missing data in 99.6% of the instances (rows). The outcome variable - as we could have seen with `info()` already - has no missing data, as it is not present in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series with type of each variable (variable, column) in df_orig.\n",
    "ps_missing_type    = df_orig.dtypes\n",
    "\n",
    "# Number of missing data per variable.\n",
    "ps_missing_total   = df_orig.isnull().sum()\n",
    "\n",
    "# Percentage of missing per variable.\n",
    "ps_missing_percent = round(100 * ps_missing_total / df_orig.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables having missing data: 27 (out of 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>empty_total</th>\n",
       "      <th>empty_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pool QC</th>\n",
       "      <td>object</td>\n",
       "      <td>2917</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misc Feature</th>\n",
       "      <td>object</td>\n",
       "      <td>2824</td>\n",
       "      <td>96.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>object</td>\n",
       "      <td>2732</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>object</td>\n",
       "      <td>2358</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <td>object</td>\n",
       "      <td>1775</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <td>object</td>\n",
       "      <td>1422</td>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Frontage</th>\n",
       "      <td>float64</td>\n",
       "      <td>490</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Cond</th>\n",
       "      <td>object</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Finish</th>\n",
       "      <td>object</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <td>float64</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Qual</th>\n",
       "      <td>object</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Type</th>\n",
       "      <td>object</td>\n",
       "      <td>157</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <td>object</td>\n",
       "      <td>83</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <td>object</td>\n",
       "      <td>81</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <td>float64</td>\n",
       "      <td>23</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Cars</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Area</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data_type  empty_total  empty_perc\n",
       "Pool QC           object         2917        99.6\n",
       "Misc Feature      object         2824        96.4\n",
       "Alley             object         2732        93.2\n",
       "Fence             object         2358        80.5\n",
       "Mas Vnr Type      object         1775        60.6\n",
       "Fireplace Qu      object         1422        48.5\n",
       "Lot Frontage     float64          490        16.7\n",
       "Garage Cond       object          159         5.4\n",
       "Garage Finish     object          159         5.4\n",
       "Garage Yr Blt    float64          159         5.4\n",
       "Garage Qual       object          159         5.4\n",
       "Garage Type       object          157         5.4\n",
       "Bsmt Exposure     object           83         2.8\n",
       "BsmtFin Type 2    object           81         2.8\n",
       "Bsmt Qual         object           80         2.7\n",
       "Bsmt Cond         object           80         2.7\n",
       "BsmtFin Type 1    object           80         2.7\n",
       "Mas Vnr Area     float64           23         0.8\n",
       "Bsmt Full Bath   float64            2         0.1\n",
       "Bsmt Half Bath   float64            2         0.1\n",
       "BsmtFin SF 1     float64            1         0.0\n",
       "Garage Cars      float64            1         0.0\n",
       "Electrical        object            1         0.0\n",
       "Total Bsmt SF    float64            1         0.0\n",
       "Bsmt Unf SF      float64            1         0.0\n",
       "BsmtFin SF 2     float64            1         0.0\n",
       "Garage Area      float64            1         0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table (Pandas DataFrame).\n",
    "df_missing_data = pd.DataFrame({\n",
    "\n",
    "    'data_type':   ps_missing_type,\n",
    "    'empty_total': ps_missing_total,\n",
    "    'empty_perc':  ps_missing_percent\n",
    "})\n",
    "\n",
    "# Sort table by number of missing data in descending order.\n",
    "df_missing_data.sort_values(\n",
    "    by        = 'empty_total',\n",
    "    ascending = False,\n",
    "    inplace   = True\n",
    ")\n",
    "\n",
    "# Remove variables that have no missing values.\n",
    "df_missing_data = df_missing_data.query(\"empty_total > 0\")\n",
    "\n",
    "# Show table.\n",
    "print(\n",
    "    f\"Number of variables having missing data: \"\n",
    "    f\"{df_missing_data.shape[0]} (out of {df_orig.shape[1]})\"\n",
    ")\n",
    "\n",
    "df_missing_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Conduct descriptive/summary statistics for numerical variables (e.g., mean, median, std, range) and for categorical variables (e.g., number of unique values, mode, and their frequency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` function outputs some descriptive statistics. For numerical data these stats include: count of non-null values, mean, standard deviation, range (i.e., min and max), the lower quartile, the median, and the upper quartile. Note, `df_orig.describe(include='number')` gives the same output. What can we conclude for the 'SalePrice' variable (min, max, median vs average)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2930.00</td>\n",
       "      <td>2.93e+03</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2440.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2907.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2928.00</td>\n",
       "      <td>2928.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2771.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1465.50</td>\n",
       "      <td>7.14e+08</td>\n",
       "      <td>57.39</td>\n",
       "      <td>69.22</td>\n",
       "      <td>10147.92</td>\n",
       "      <td>6.09</td>\n",
       "      <td>5.56</td>\n",
       "      <td>1971.36</td>\n",
       "      <td>1984.27</td>\n",
       "      <td>101.90</td>\n",
       "      <td>442.63</td>\n",
       "      <td>49.72</td>\n",
       "      <td>559.26</td>\n",
       "      <td>1051.61</td>\n",
       "      <td>1159.56</td>\n",
       "      <td>335.46</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1499.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.04</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1978.13</td>\n",
       "      <td>1.77</td>\n",
       "      <td>472.82</td>\n",
       "      <td>93.75</td>\n",
       "      <td>47.53</td>\n",
       "      <td>23.01</td>\n",
       "      <td>2.59</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>50.64</td>\n",
       "      <td>6.22</td>\n",
       "      <td>2007.79</td>\n",
       "      <td>180796.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>845.96</td>\n",
       "      <td>1.89e+08</td>\n",
       "      <td>42.64</td>\n",
       "      <td>23.37</td>\n",
       "      <td>7880.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.11</td>\n",
       "      <td>30.25</td>\n",
       "      <td>20.86</td>\n",
       "      <td>179.11</td>\n",
       "      <td>455.59</td>\n",
       "      <td>169.17</td>\n",
       "      <td>439.49</td>\n",
       "      <td>440.62</td>\n",
       "      <td>391.89</td>\n",
       "      <td>428.40</td>\n",
       "      <td>46.31</td>\n",
       "      <td>505.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>25.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>215.05</td>\n",
       "      <td>126.36</td>\n",
       "      <td>67.48</td>\n",
       "      <td>64.14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>56.09</td>\n",
       "      <td>35.60</td>\n",
       "      <td>566.34</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.32</td>\n",
       "      <td>79886.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.26e+08</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1872.00</td>\n",
       "      <td>1950.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>334.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>334.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1895.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2006.00</td>\n",
       "      <td>12789.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>733.25</td>\n",
       "      <td>5.28e+08</td>\n",
       "      <td>20.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>7440.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1954.00</td>\n",
       "      <td>1965.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.00</td>\n",
       "      <td>793.00</td>\n",
       "      <td>876.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1126.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1960.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>129500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1465.50</td>\n",
       "      <td>5.35e+08</td>\n",
       "      <td>50.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>9436.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1973.00</td>\n",
       "      <td>1993.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>370.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>990.00</td>\n",
       "      <td>1084.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1442.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1979.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>480.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>160000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2197.75</td>\n",
       "      <td>9.07e+08</td>\n",
       "      <td>70.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>11555.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2001.00</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>164.00</td>\n",
       "      <td>734.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>802.00</td>\n",
       "      <td>1302.00</td>\n",
       "      <td>1384.00</td>\n",
       "      <td>703.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1742.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>576.00</td>\n",
       "      <td>168.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>213500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.00</td>\n",
       "      <td>1.01e+09</td>\n",
       "      <td>190.00</td>\n",
       "      <td>313.00</td>\n",
       "      <td>215245.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>5644.00</td>\n",
       "      <td>1526.00</td>\n",
       "      <td>2336.00</td>\n",
       "      <td>6110.00</td>\n",
       "      <td>5095.00</td>\n",
       "      <td>2065.00</td>\n",
       "      <td>1064.00</td>\n",
       "      <td>5642.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2207.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1488.00</td>\n",
       "      <td>1424.00</td>\n",
       "      <td>742.00</td>\n",
       "      <td>1012.00</td>\n",
       "      <td>508.00</td>\n",
       "      <td>576.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>755000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order       PID  MS SubClass  Lot Frontage   Lot Area  Overall Qual  \\\n",
       "count  2930.00  2.93e+03      2930.00       2440.00    2930.00       2930.00   \n",
       "mean   1465.50  7.14e+08        57.39         69.22   10147.92          6.09   \n",
       "std     845.96  1.89e+08        42.64         23.37    7880.02          1.41   \n",
       "min       1.00  5.26e+08        20.00         21.00    1300.00          1.00   \n",
       "25%     733.25  5.28e+08        20.00         58.00    7440.25          5.00   \n",
       "50%    1465.50  5.35e+08        50.00         68.00    9436.50          6.00   \n",
       "75%    2197.75  9.07e+08        70.00         80.00   11555.25          7.00   \n",
       "max    2930.00  1.01e+09       190.00        313.00  215245.00         10.00   \n",
       "\n",
       "       Overall Cond  Year Built  Year Remod/Add  Mas Vnr Area  BsmtFin SF 1  \\\n",
       "count       2930.00     2930.00         2930.00       2907.00       2929.00   \n",
       "mean           5.56     1971.36         1984.27        101.90        442.63   \n",
       "std            1.11       30.25           20.86        179.11        455.59   \n",
       "min            1.00     1872.00         1950.00          0.00          0.00   \n",
       "25%            5.00     1954.00         1965.00          0.00          0.00   \n",
       "50%            5.00     1973.00         1993.00          0.00        370.00   \n",
       "75%            6.00     2001.00         2004.00        164.00        734.00   \n",
       "max            9.00     2010.00         2010.00       1600.00       5644.00   \n",
       "\n",
       "       BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF  1st Flr SF  2nd Flr SF  \\\n",
       "count       2929.00      2929.00        2929.00     2930.00     2930.00   \n",
       "mean          49.72       559.26        1051.61     1159.56      335.46   \n",
       "std          169.17       439.49         440.62      391.89      428.40   \n",
       "min            0.00         0.00           0.00      334.00        0.00   \n",
       "25%            0.00       219.00         793.00      876.25        0.00   \n",
       "50%            0.00       466.00         990.00     1084.00        0.00   \n",
       "75%            0.00       802.00        1302.00     1384.00      703.75   \n",
       "max         1526.00      2336.00        6110.00     5095.00     2065.00   \n",
       "\n",
       "       Low Qual Fin SF  Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath  \\\n",
       "count          2930.00      2930.00         2928.00         2928.00   \n",
       "mean              4.68      1499.69            0.43            0.06   \n",
       "std              46.31       505.51            0.52            0.25   \n",
       "min               0.00       334.00            0.00            0.00   \n",
       "25%               0.00      1126.00            0.00            0.00   \n",
       "50%               0.00      1442.00            0.00            0.00   \n",
       "75%               0.00      1742.75            1.00            0.00   \n",
       "max            1064.00      5642.00            3.00            2.00   \n",
       "\n",
       "       Full Bath  Half Bath  Bedroom AbvGr  Kitchen AbvGr  TotRms AbvGrd  \\\n",
       "count    2930.00    2930.00        2930.00        2930.00        2930.00   \n",
       "mean        1.57       0.38           2.85           1.04           6.44   \n",
       "std         0.55       0.50           0.83           0.21           1.57   \n",
       "min         0.00       0.00           0.00           0.00           2.00   \n",
       "25%         1.00       0.00           2.00           1.00           5.00   \n",
       "50%         2.00       0.00           3.00           1.00           6.00   \n",
       "75%         2.00       1.00           3.00           1.00           7.00   \n",
       "max         4.00       2.00           8.00           3.00          15.00   \n",
       "\n",
       "       Fireplaces  Garage Yr Blt  Garage Cars  Garage Area  Wood Deck SF  \\\n",
       "count     2930.00        2771.00      2929.00      2929.00       2930.00   \n",
       "mean         0.60        1978.13         1.77       472.82         93.75   \n",
       "std          0.65          25.53         0.76       215.05        126.36   \n",
       "min          0.00        1895.00         0.00         0.00          0.00   \n",
       "25%          0.00        1960.00         1.00       320.00          0.00   \n",
       "50%          1.00        1979.00         2.00       480.00          0.00   \n",
       "75%          1.00        2002.00         2.00       576.00        168.00   \n",
       "max          4.00        2207.00         5.00      1488.00       1424.00   \n",
       "\n",
       "       Open Porch SF  Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area  \\\n",
       "count        2930.00         2930.00     2930.00       2930.00    2930.00   \n",
       "mean           47.53           23.01        2.59         16.00       2.24   \n",
       "std            67.48           64.14       25.14         56.09      35.60   \n",
       "min             0.00            0.00        0.00          0.00       0.00   \n",
       "25%             0.00            0.00        0.00          0.00       0.00   \n",
       "50%            27.00            0.00        0.00          0.00       0.00   \n",
       "75%            70.00            0.00        0.00          0.00       0.00   \n",
       "max           742.00         1012.00      508.00        576.00     800.00   \n",
       "\n",
       "       Misc Val  Mo Sold  Yr Sold  SalePrice  \n",
       "count   2930.00  2930.00  2930.00    2930.00  \n",
       "mean      50.64     6.22  2007.79  180796.06  \n",
       "std      566.34     2.71     1.32   79886.69  \n",
       "min        0.00     1.00  2006.00   12789.00  \n",
       "25%        0.00     4.00  2007.00  129500.00  \n",
       "50%        0.00     6.00  2008.00  160000.00  \n",
       "75%        0.00     8.00  2009.00  213500.00  \n",
       "max    17000.00    12.00  2010.00  755000.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num_orig.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other descriptive statistics exist for object data. These include: count of non-null values, number of unique values, value with highest frequency, and the frequency at which said value is present. E.g., what can we conclude for the 'Street' variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Roof Style</th>\n",
       "      <th>Roof Matl</th>\n",
       "      <th>Exterior 1st</th>\n",
       "      <th>Exterior 2nd</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Heating QC</th>\n",
       "      <th>Central Air</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "      <th>Paved Drive</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>198</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>1155</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2847</td>\n",
       "      <td>2850</td>\n",
       "      <td>2849</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2929</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>1508</td>\n",
       "      <td>2773</td>\n",
       "      <td>2771</td>\n",
       "      <td>2771</td>\n",
       "      <td>2771</td>\n",
       "      <td>2930</td>\n",
       "      <td>13</td>\n",
       "      <td>572</td>\n",
       "      <td>106</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Ex</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2273</td>\n",
       "      <td>2918</td>\n",
       "      <td>120</td>\n",
       "      <td>1859</td>\n",
       "      <td>2633</td>\n",
       "      <td>2927</td>\n",
       "      <td>2140</td>\n",
       "      <td>2789</td>\n",
       "      <td>443</td>\n",
       "      <td>2522</td>\n",
       "      <td>2900</td>\n",
       "      <td>2425</td>\n",
       "      <td>1481</td>\n",
       "      <td>2321</td>\n",
       "      <td>2887</td>\n",
       "      <td>1026</td>\n",
       "      <td>1015</td>\n",
       "      <td>880</td>\n",
       "      <td>1799</td>\n",
       "      <td>2549</td>\n",
       "      <td>1310</td>\n",
       "      <td>1283</td>\n",
       "      <td>2616</td>\n",
       "      <td>1906</td>\n",
       "      <td>859</td>\n",
       "      <td>2499</td>\n",
       "      <td>2885</td>\n",
       "      <td>1495</td>\n",
       "      <td>2734</td>\n",
       "      <td>2682</td>\n",
       "      <td>1494</td>\n",
       "      <td>2728</td>\n",
       "      <td>744</td>\n",
       "      <td>1731</td>\n",
       "      <td>1231</td>\n",
       "      <td>2615</td>\n",
       "      <td>2665</td>\n",
       "      <td>2652</td>\n",
       "      <td>4</td>\n",
       "      <td>330</td>\n",
       "      <td>95</td>\n",
       "      <td>2536</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MS Zoning Street Alley Lot Shape Land Contour Utilities Lot Config  \\\n",
       "count       2930   2930   198      2930         2930      2930       2930   \n",
       "unique         7      2     2         4            4         3          5   \n",
       "top           RL   Pave  Grvl       Reg          Lvl    AllPub     Inside   \n",
       "freq        2273   2918   120      1859         2633      2927       2140   \n",
       "\n",
       "       Land Slope Neighborhood Condition 1 Condition 2 Bldg Type House Style  \\\n",
       "count        2930         2930        2930        2930      2930        2930   \n",
       "unique          3           28           9           8         5           8   \n",
       "top           Gtl        NAmes        Norm        Norm      1Fam      1Story   \n",
       "freq         2789          443        2522        2900      2425        1481   \n",
       "\n",
       "       Roof Style Roof Matl Exterior 1st Exterior 2nd Mas Vnr Type Exter Qual  \\\n",
       "count        2930      2930         2930         2930         1155       2930   \n",
       "unique          6         8           16           17            4          4   \n",
       "top         Gable   CompShg      VinylSd      VinylSd      BrkFace         TA   \n",
       "freq         2321      2887         1026         1015          880       1799   \n",
       "\n",
       "       Exter Cond Foundation Bsmt Qual Bsmt Cond Bsmt Exposure BsmtFin Type 1  \\\n",
       "count        2930       2930      2850      2850          2847           2850   \n",
       "unique          5          6         5         5             4              6   \n",
       "top            TA      PConc        TA        TA            No            GLQ   \n",
       "freq         2549       1310      1283      2616          1906            859   \n",
       "\n",
       "       BsmtFin Type 2 Heating Heating QC Central Air Electrical Kitchen Qual  \\\n",
       "count            2849    2930       2930        2930       2929         2930   \n",
       "unique              6       6          5           2          5            5   \n",
       "top               Unf    GasA         Ex           Y      SBrkr           TA   \n",
       "freq             2499    2885       1495        2734       2682         1494   \n",
       "\n",
       "       Functional Fireplace Qu Garage Type Garage Finish Garage Qual  \\\n",
       "count        2930         1508        2773          2771        2771   \n",
       "unique          8            5           6             3           5   \n",
       "top           Typ           Gd      Attchd           Unf          TA   \n",
       "freq         2728          744        1731          1231        2615   \n",
       "\n",
       "       Garage Cond Paved Drive Pool QC  Fence Misc Feature Sale Type  \\\n",
       "count         2771        2930      13    572          106      2930   \n",
       "unique           5           3       4      4            5        10   \n",
       "top             TA           Y      Ex  MnPrv         Shed       WD    \n",
       "freq          2665        2652       4    330           95      2536   \n",
       "\n",
       "       Sale Condition  \n",
       "count            2930  \n",
       "unique              6  \n",
       "top            Normal  \n",
       "freq             2413  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_orig.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Extra - An alternative solution to descriptive statistics using `f_describe()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you explore data in data frames, you will develop your own scripts based on your preferences. In case you apply the same script in more than two places, I advise you to consider placing that script in a function. This allows you to apply that script by simply referencing to the name you gave to the function, see also Python Explainer `Functions`.\n",
    "\n",
    "To pull out a few more descriptive statistics, I developed my own describe function `f_describe()`, which is part of the utils_pieter package. It is a kind of a do-all-in-one function to obtain descriptive statistics on all variables in the data, numeric and categoric.\n",
    "\n",
    "Note, it is not mandatory to use keyword arguments. The script `f_describe(df, 10)` results in the same output as `f_describe(df_input = df, n_top = 3)`, since the values are provided in the same order as the keyword argument pairs. For functions with multiple arguments, I recommend you to use keyword arguments to prevent the risk of assigning values to the wrong argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data:\n",
      "\n",
      "-> Name:            'df_orig'\n",
      "\n",
      "-> Dimension:        2930 rows and 82 columns.\n",
      "\n",
      "-> Size:             7.8 MB.\n",
      "\n",
      "-> Integer columns:  1st Flr SF, 2nd Flr SF, 3Ssn Porch, Bedroom AbvGr, Enclosed Porch, Fireplaces, Full Bath, Gr Liv Area, Half Bath, Kitchen AbvGr, Lot Area, Low Qual Fin SF, MS SubClass, Misc Val, Mo Sold, Open Porch SF, Order, Overall Cond, Overall Qual, PID, Pool Area, SalePrice, Screen Porch, TotRms AbvGrd, Wood Deck SF, Year Built, Year Remod/Add, Yr Sold.\n",
      "\n",
      "-> Float columns:    Bsmt Full Bath, Bsmt Half Bath, Bsmt Unf SF, BsmtFin SF 1, BsmtFin SF 2, Garage Area, Garage Cars, Garage Yr Blt, Lot Frontage, Mas Vnr Area, Total Bsmt SF.\n",
      "\n",
      "-> String columns:   Alley, Bldg Type, Bsmt Cond, Bsmt Exposure, Bsmt Qual, BsmtFin Type 1, BsmtFin Type 2, Central Air, Condition 1, Condition 2, Electrical, Exter Cond, Exter Qual, Exterior 1st, Exterior 2nd, Fence, Fireplace Qu, Foundation, Functional, Garage Cond, Garage Finish, Garage Qual, Garage Type, Heating, Heating QC, House Style, Kitchen Qual, Land Contour, Land Slope, Lot Config, Lot Shape, MS Zoning, Mas Vnr Type, Misc Feature, Neighborhood, Paved Drive, Pool QC, Roof Matl, Roof Style, Sale Condition, Sale Type, Street, Utilities.\n",
      "\n",
      "\n",
      "Show data (first 3 rows, this number can be altered through 'n_top' in the function call):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Roof Style</th>\n",
       "      <th>Roof Matl</th>\n",
       "      <th>Exterior 1st</th>\n",
       "      <th>Exterior 2nd</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Heating QC</th>\n",
       "      <th>Central Air</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "      <th>Paved Drive</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Stone</td>\n",
       "      <td>112.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>639.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Fa</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>P</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468.0</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>108.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour Utilities Lot Config Land Slope Neighborhood  \\\n",
       "0   NaN       IR1          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "1   NaN       Reg          Lvl    AllPub     Inside        Gtl        NAmes   \n",
       "2   NaN       IR1          Lvl    AllPub     Corner        Gtl        NAmes   \n",
       "\n",
       "  Condition 1 Condition 2 Bldg Type House Style  Overall Qual  Overall Cond  \\\n",
       "0        Norm        Norm      1Fam      1Story             6             5   \n",
       "1       Feedr        Norm      1Fam      1Story             5             6   \n",
       "2        Norm        Norm      1Fam      1Story             6             6   \n",
       "\n",
       "   Year Built  Year Remod/Add Roof Style Roof Matl Exterior 1st Exterior 2nd  \\\n",
       "0        1960            1960        Hip   CompShg      BrkFace      Plywood   \n",
       "1        1961            1961      Gable   CompShg      VinylSd      VinylSd   \n",
       "2        1958            1958        Hip   CompShg      Wd Sdng      Wd Sdng   \n",
       "\n",
       "  Mas Vnr Type  Mas Vnr Area Exter Qual Exter Cond Foundation Bsmt Qual  \\\n",
       "0        Stone         112.0         TA         TA     CBlock        TA   \n",
       "1          NaN           0.0         TA         TA     CBlock        TA   \n",
       "2      BrkFace         108.0         TA         TA     CBlock        TA   \n",
       "\n",
       "  Bsmt Cond Bsmt Exposure BsmtFin Type 1  BsmtFin SF 1 BsmtFin Type 2  \\\n",
       "0        Gd            Gd            BLQ         639.0            Unf   \n",
       "1        TA            No            Rec         468.0            LwQ   \n",
       "2        TA            No            ALQ         923.0            Unf   \n",
       "\n",
       "   BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF Heating Heating QC Central Air  \\\n",
       "0           0.0        441.0         1080.0    GasA         Fa           Y   \n",
       "1         144.0        270.0          882.0    GasA         TA           Y   \n",
       "2           0.0        406.0         1329.0    GasA         TA           Y   \n",
       "\n",
       "  Electrical  1st Flr SF  2nd Flr SF  Low Qual Fin SF  Gr Liv Area  \\\n",
       "0      SBrkr        1656           0                0         1656   \n",
       "1      SBrkr         896           0                0          896   \n",
       "2      SBrkr        1329           0                0         1329   \n",
       "\n",
       "   Bsmt Full Bath  Bsmt Half Bath  Full Bath  Half Bath  Bedroom AbvGr  \\\n",
       "0             1.0             0.0          1          0              3   \n",
       "1             0.0             0.0          1          0              2   \n",
       "2             0.0             0.0          1          1              3   \n",
       "\n",
       "   Kitchen AbvGr Kitchen Qual  TotRms AbvGrd Functional  Fireplaces  \\\n",
       "0              1           TA              7        Typ           2   \n",
       "1              1           TA              5        Typ           0   \n",
       "2              1           Gd              6        Typ           0   \n",
       "\n",
       "  Fireplace Qu Garage Type  Garage Yr Blt Garage Finish  Garage Cars  \\\n",
       "0           Gd      Attchd         1960.0           Fin          2.0   \n",
       "1          NaN      Attchd         1961.0           Unf          1.0   \n",
       "2          NaN      Attchd         1958.0           Unf          1.0   \n",
       "\n",
       "   Garage Area Garage Qual Garage Cond Paved Drive  Wood Deck SF  \\\n",
       "0        528.0          TA          TA           P           210   \n",
       "1        730.0          TA          TA           Y           140   \n",
       "2        312.0          TA          TA           Y           393   \n",
       "\n",
       "   Open Porch SF  Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area Pool QC  \\\n",
       "0             62               0           0             0          0     NaN   \n",
       "1              0               0           0           120          0     NaN   \n",
       "2             36               0           0             0          0     NaN   \n",
       "\n",
       "   Fence Misc Feature  Misc Val  Mo Sold  Yr Sold Sale Type Sale Condition  \\\n",
       "0    NaN          NaN         0        5     2010       WD          Normal   \n",
       "1  MnPrv          NaN         0        6     2010       WD          Normal   \n",
       "2    NaN         Gar2     12500        6     2010       WD          Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     215000  \n",
       "1     105000  \n",
       "2     172000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Describe integer data (28 columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2930.00</td>\n",
       "      <td>2.93e+03</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "      <td>2930.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1465.50</td>\n",
       "      <td>7.14e+08</td>\n",
       "      <td>57.39</td>\n",
       "      <td>10147.92</td>\n",
       "      <td>6.09</td>\n",
       "      <td>5.56</td>\n",
       "      <td>1971.36</td>\n",
       "      <td>1984.27</td>\n",
       "      <td>1159.56</td>\n",
       "      <td>335.46</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1499.69</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.04</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>93.75</td>\n",
       "      <td>47.53</td>\n",
       "      <td>23.01</td>\n",
       "      <td>2.59</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>50.64</td>\n",
       "      <td>6.22</td>\n",
       "      <td>2007.79</td>\n",
       "      <td>180796.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>845.96</td>\n",
       "      <td>1.89e+08</td>\n",
       "      <td>42.64</td>\n",
       "      <td>7880.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.11</td>\n",
       "      <td>30.25</td>\n",
       "      <td>20.86</td>\n",
       "      <td>391.89</td>\n",
       "      <td>428.40</td>\n",
       "      <td>46.31</td>\n",
       "      <td>505.51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>126.36</td>\n",
       "      <td>67.48</td>\n",
       "      <td>64.14</td>\n",
       "      <td>25.14</td>\n",
       "      <td>56.09</td>\n",
       "      <td>35.60</td>\n",
       "      <td>566.34</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.32</td>\n",
       "      <td>79886.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.26e+08</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1872.00</td>\n",
       "      <td>1950.00</td>\n",
       "      <td>334.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>334.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2006.00</td>\n",
       "      <td>12789.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>733.25</td>\n",
       "      <td>5.28e+08</td>\n",
       "      <td>20.00</td>\n",
       "      <td>7440.25</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1954.00</td>\n",
       "      <td>1965.00</td>\n",
       "      <td>876.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1126.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2007.00</td>\n",
       "      <td>129500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1465.50</td>\n",
       "      <td>5.35e+08</td>\n",
       "      <td>50.00</td>\n",
       "      <td>9436.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1973.00</td>\n",
       "      <td>1993.00</td>\n",
       "      <td>1084.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1442.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2008.00</td>\n",
       "      <td>160000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2197.75</td>\n",
       "      <td>9.07e+08</td>\n",
       "      <td>70.00</td>\n",
       "      <td>11555.25</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2001.00</td>\n",
       "      <td>2004.00</td>\n",
       "      <td>1384.00</td>\n",
       "      <td>703.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1742.75</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>168.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>213500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.00</td>\n",
       "      <td>1.01e+09</td>\n",
       "      <td>190.00</td>\n",
       "      <td>215245.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>5095.00</td>\n",
       "      <td>2065.00</td>\n",
       "      <td>1064.00</td>\n",
       "      <td>5642.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1424.00</td>\n",
       "      <td>742.00</td>\n",
       "      <td>1012.00</td>\n",
       "      <td>508.00</td>\n",
       "      <td>576.00</td>\n",
       "      <td>800.00</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>755000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order       PID  MS SubClass   Lot Area  Overall Qual  Overall Cond  \\\n",
       "count  2930.00  2.93e+03      2930.00    2930.00       2930.00       2930.00   \n",
       "mean   1465.50  7.14e+08        57.39   10147.92          6.09          5.56   \n",
       "std     845.96  1.89e+08        42.64    7880.02          1.41          1.11   \n",
       "min       1.00  5.26e+08        20.00    1300.00          1.00          1.00   \n",
       "25%     733.25  5.28e+08        20.00    7440.25          5.00          5.00   \n",
       "50%    1465.50  5.35e+08        50.00    9436.50          6.00          5.00   \n",
       "75%    2197.75  9.07e+08        70.00   11555.25          7.00          6.00   \n",
       "max    2930.00  1.01e+09       190.00  215245.00         10.00          9.00   \n",
       "\n",
       "       Year Built  Year Remod/Add  1st Flr SF  2nd Flr SF  Low Qual Fin SF  \\\n",
       "count     2930.00         2930.00     2930.00     2930.00          2930.00   \n",
       "mean      1971.36         1984.27     1159.56      335.46             4.68   \n",
       "std         30.25           20.86      391.89      428.40            46.31   \n",
       "min       1872.00         1950.00      334.00        0.00             0.00   \n",
       "25%       1954.00         1965.00      876.25        0.00             0.00   \n",
       "50%       1973.00         1993.00     1084.00        0.00             0.00   \n",
       "75%       2001.00         2004.00     1384.00      703.75             0.00   \n",
       "max       2010.00         2010.00     5095.00     2065.00          1064.00   \n",
       "\n",
       "       Gr Liv Area  Full Bath  Half Bath  Bedroom AbvGr  Kitchen AbvGr  \\\n",
       "count      2930.00    2930.00    2930.00        2930.00        2930.00   \n",
       "mean       1499.69       1.57       0.38           2.85           1.04   \n",
       "std         505.51       0.55       0.50           0.83           0.21   \n",
       "min         334.00       0.00       0.00           0.00           0.00   \n",
       "25%        1126.00       1.00       0.00           2.00           1.00   \n",
       "50%        1442.00       2.00       0.00           3.00           1.00   \n",
       "75%        1742.75       2.00       1.00           3.00           1.00   \n",
       "max        5642.00       4.00       2.00           8.00           3.00   \n",
       "\n",
       "       TotRms AbvGrd  Fireplaces  Wood Deck SF  Open Porch SF  Enclosed Porch  \\\n",
       "count        2930.00     2930.00       2930.00        2930.00         2930.00   \n",
       "mean            6.44        0.60         93.75          47.53           23.01   \n",
       "std             1.57        0.65        126.36          67.48           64.14   \n",
       "min             2.00        0.00          0.00           0.00            0.00   \n",
       "25%             5.00        0.00          0.00           0.00            0.00   \n",
       "50%             6.00        1.00          0.00          27.00            0.00   \n",
       "75%             7.00        1.00        168.00          70.00            0.00   \n",
       "max            15.00        4.00       1424.00         742.00         1012.00   \n",
       "\n",
       "       3Ssn Porch  Screen Porch  Pool Area  Misc Val  Mo Sold  Yr Sold  \\\n",
       "count     2930.00       2930.00    2930.00   2930.00  2930.00  2930.00   \n",
       "mean         2.59         16.00       2.24     50.64     6.22  2007.79   \n",
       "std         25.14         56.09      35.60    566.34     2.71     1.32   \n",
       "min          0.00          0.00       0.00      0.00     1.00  2006.00   \n",
       "25%          0.00          0.00       0.00      0.00     4.00  2007.00   \n",
       "50%          0.00          0.00       0.00      0.00     6.00  2008.00   \n",
       "75%          0.00          0.00       0.00      0.00     8.00  2009.00   \n",
       "max        508.00        576.00     800.00  17000.00    12.00  2010.00   \n",
       "\n",
       "       SalePrice  \n",
       "count    2930.00  \n",
       "mean   180796.06  \n",
       "std     79886.69  \n",
       "min     12789.00  \n",
       "25%    129500.00  \n",
       "50%    160000.00  \n",
       "75%    213500.00  \n",
       "max    755000.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Describe floating data (11 columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2440.00</td>\n",
       "      <td>2907.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2928.00</td>\n",
       "      <td>2928.00</td>\n",
       "      <td>2771.00</td>\n",
       "      <td>2929.00</td>\n",
       "      <td>2929.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.22</td>\n",
       "      <td>101.90</td>\n",
       "      <td>442.63</td>\n",
       "      <td>49.72</td>\n",
       "      <td>559.26</td>\n",
       "      <td>1051.61</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1978.13</td>\n",
       "      <td>1.77</td>\n",
       "      <td>472.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.37</td>\n",
       "      <td>179.11</td>\n",
       "      <td>455.59</td>\n",
       "      <td>169.17</td>\n",
       "      <td>439.49</td>\n",
       "      <td>440.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.53</td>\n",
       "      <td>0.76</td>\n",
       "      <td>215.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1895.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.00</td>\n",
       "      <td>793.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1960.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>320.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>370.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>990.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1979.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>480.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>80.00</td>\n",
       "      <td>164.00</td>\n",
       "      <td>734.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>802.00</td>\n",
       "      <td>1302.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2002.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>576.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>313.00</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>5644.00</td>\n",
       "      <td>1526.00</td>\n",
       "      <td>2336.00</td>\n",
       "      <td>6110.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2207.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1488.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lot Frontage  Mas Vnr Area  BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  \\\n",
       "count       2440.00       2907.00       2929.00       2929.00      2929.00   \n",
       "mean          69.22        101.90        442.63         49.72       559.26   \n",
       "std           23.37        179.11        455.59        169.17       439.49   \n",
       "min           21.00          0.00          0.00          0.00         0.00   \n",
       "25%           58.00          0.00          0.00          0.00       219.00   \n",
       "50%           68.00          0.00        370.00          0.00       466.00   \n",
       "75%           80.00        164.00        734.00          0.00       802.00   \n",
       "max          313.00       1600.00       5644.00       1526.00      2336.00   \n",
       "\n",
       "       Total Bsmt SF  Bsmt Full Bath  Bsmt Half Bath  Garage Yr Blt  \\\n",
       "count        2929.00         2928.00         2928.00        2771.00   \n",
       "mean         1051.61            0.43            0.06        1978.13   \n",
       "std           440.62            0.52            0.25          25.53   \n",
       "min             0.00            0.00            0.00        1895.00   \n",
       "25%           793.00            0.00            0.00        1960.00   \n",
       "50%           990.00            0.00            0.00        1979.00   \n",
       "75%          1302.00            1.00            0.00        2002.00   \n",
       "max          6110.00            3.00            2.00        2207.00   \n",
       "\n",
       "       Garage Cars  Garage Area  \n",
       "count      2929.00      2929.00  \n",
       "mean          1.77       472.82  \n",
       "std           0.76       215.05  \n",
       "min           0.00         0.00  \n",
       "25%           1.00       320.00  \n",
       "50%           2.00       480.00  \n",
       "75%           2.00       576.00  \n",
       "max           5.00      1488.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Describe string data (43 columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Roof Style</th>\n",
       "      <th>Roof Matl</th>\n",
       "      <th>Exterior 1st</th>\n",
       "      <th>Exterior 2nd</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Heating QC</th>\n",
       "      <th>Central Air</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "      <th>Paved Drive</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>198</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>1155</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2847</td>\n",
       "      <td>2850</td>\n",
       "      <td>2849</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>2929</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "      <td>1508</td>\n",
       "      <td>2773</td>\n",
       "      <td>2771</td>\n",
       "      <td>2771</td>\n",
       "      <td>2771</td>\n",
       "      <td>2930</td>\n",
       "      <td>13</td>\n",
       "      <td>572</td>\n",
       "      <td>106</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Ex</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2273</td>\n",
       "      <td>2918</td>\n",
       "      <td>120</td>\n",
       "      <td>1859</td>\n",
       "      <td>2633</td>\n",
       "      <td>2927</td>\n",
       "      <td>2140</td>\n",
       "      <td>2789</td>\n",
       "      <td>443</td>\n",
       "      <td>2522</td>\n",
       "      <td>2900</td>\n",
       "      <td>2425</td>\n",
       "      <td>1481</td>\n",
       "      <td>2321</td>\n",
       "      <td>2887</td>\n",
       "      <td>1026</td>\n",
       "      <td>1015</td>\n",
       "      <td>880</td>\n",
       "      <td>1799</td>\n",
       "      <td>2549</td>\n",
       "      <td>1310</td>\n",
       "      <td>1283</td>\n",
       "      <td>2616</td>\n",
       "      <td>1906</td>\n",
       "      <td>859</td>\n",
       "      <td>2499</td>\n",
       "      <td>2885</td>\n",
       "      <td>1495</td>\n",
       "      <td>2734</td>\n",
       "      <td>2682</td>\n",
       "      <td>1494</td>\n",
       "      <td>2728</td>\n",
       "      <td>744</td>\n",
       "      <td>1731</td>\n",
       "      <td>1231</td>\n",
       "      <td>2615</td>\n",
       "      <td>2665</td>\n",
       "      <td>2652</td>\n",
       "      <td>4</td>\n",
       "      <td>330</td>\n",
       "      <td>95</td>\n",
       "      <td>2536</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MS Zoning Street Alley Lot Shape Land Contour Utilities Lot Config  \\\n",
       "count       2930   2930   198      2930         2930      2930       2930   \n",
       "unique         7      2     2         4            4         3          5   \n",
       "top           RL   Pave  Grvl       Reg          Lvl    AllPub     Inside   \n",
       "freq        2273   2918   120      1859         2633      2927       2140   \n",
       "\n",
       "       Land Slope Neighborhood Condition 1 Condition 2 Bldg Type House Style  \\\n",
       "count        2930         2930        2930        2930      2930        2930   \n",
       "unique          3           28           9           8         5           8   \n",
       "top           Gtl        NAmes        Norm        Norm      1Fam      1Story   \n",
       "freq         2789          443        2522        2900      2425        1481   \n",
       "\n",
       "       Roof Style Roof Matl Exterior 1st Exterior 2nd Mas Vnr Type Exter Qual  \\\n",
       "count        2930      2930         2930         2930         1155       2930   \n",
       "unique          6         8           16           17            4          4   \n",
       "top         Gable   CompShg      VinylSd      VinylSd      BrkFace         TA   \n",
       "freq         2321      2887         1026         1015          880       1799   \n",
       "\n",
       "       Exter Cond Foundation Bsmt Qual Bsmt Cond Bsmt Exposure BsmtFin Type 1  \\\n",
       "count        2930       2930      2850      2850          2847           2850   \n",
       "unique          5          6         5         5             4              6   \n",
       "top            TA      PConc        TA        TA            No            GLQ   \n",
       "freq         2549       1310      1283      2616          1906            859   \n",
       "\n",
       "       BsmtFin Type 2 Heating Heating QC Central Air Electrical Kitchen Qual  \\\n",
       "count            2849    2930       2930        2930       2929         2930   \n",
       "unique              6       6          5           2          5            5   \n",
       "top               Unf    GasA         Ex           Y      SBrkr           TA   \n",
       "freq             2499    2885       1495        2734       2682         1494   \n",
       "\n",
       "       Functional Fireplace Qu Garage Type Garage Finish Garage Qual  \\\n",
       "count        2930         1508        2773          2771        2771   \n",
       "unique          8            5           6             3           5   \n",
       "top           Typ           Gd      Attchd           Unf          TA   \n",
       "freq         2728          744        1731          1231        2615   \n",
       "\n",
       "       Garage Cond Paved Drive Pool QC  Fence Misc Feature Sale Type  \\\n",
       "count         2771        2930      13    572          106      2930   \n",
       "unique           5           3       4      4            5        10   \n",
       "top             TA           Y      Ex  MnPrv         Shed       WD    \n",
       "freq          2665        2652       4    330           95      2536   \n",
       "\n",
       "       Sale Condition  \n",
       "count            2930  \n",
       "unique              6  \n",
       "top            Normal  \n",
       "freq             2413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Show missing data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pool QC</th>\n",
       "      <td>object</td>\n",
       "      <td>2917</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Misc Feature</th>\n",
       "      <td>object</td>\n",
       "      <td>2824</td>\n",
       "      <td>96.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>object</td>\n",
       "      <td>2732</td>\n",
       "      <td>93.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>object</td>\n",
       "      <td>2358</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <td>object</td>\n",
       "      <td>1775</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <td>object</td>\n",
       "      <td>1422</td>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Frontage</th>\n",
       "      <td>float64</td>\n",
       "      <td>490</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Cond</th>\n",
       "      <td>object</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Finish</th>\n",
       "      <td>object</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <td>float64</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Qual</th>\n",
       "      <td>object</td>\n",
       "      <td>159</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Type</th>\n",
       "      <td>object</td>\n",
       "      <td>157</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <td>object</td>\n",
       "      <td>83</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <td>object</td>\n",
       "      <td>81</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <td>float64</td>\n",
       "      <td>23</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Cars</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garage Area</th>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   type  total  percent\n",
       "Pool QC          object   2917     99.6\n",
       "Misc Feature     object   2824     96.4\n",
       "Alley            object   2732     93.2\n",
       "Fence            object   2358     80.5\n",
       "Mas Vnr Type     object   1775     60.6\n",
       "Fireplace Qu     object   1422     48.5\n",
       "Lot Frontage    float64    490     16.7\n",
       "Garage Cond      object    159      5.4\n",
       "Garage Finish    object    159      5.4\n",
       "Garage Yr Blt   float64    159      5.4\n",
       "Garage Qual      object    159      5.4\n",
       "Garage Type      object    157      5.4\n",
       "Bsmt Exposure    object     83      2.8\n",
       "BsmtFin Type 2   object     81      2.8\n",
       "Bsmt Qual        object     80      2.7\n",
       "Bsmt Cond        object     80      2.7\n",
       "BsmtFin Type 1   object     80      2.7\n",
       "Mas Vnr Area    float64     23      0.8\n",
       "Bsmt Full Bath  float64      2      0.1\n",
       "Bsmt Half Bath  float64      2      0.1\n",
       "BsmtFin SF 1    float64      1      0.0\n",
       "Garage Cars     float64      1      0.0\n",
       "Electrical       object      1      0.0\n",
       "Total Bsmt SF   float64      1      0.0\n",
       "Bsmt Unf SF     float64      1      0.0\n",
       "BsmtFin SF 2    float64      1      0.0\n",
       "Garage Area     float64      1      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "up.f_describe(df_input = df_orig, n_top = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` method only provides the mode, i.e., the value in a categorical variable present at the highest frequency. Suppose we want to investigate the frequency of the values for any variable. For that I developed the function `f_info()`. By default, the top-10 items are shown. In case the variable has more than ten items - e.g., `Neighborhood` - you can add input parameter 'n_top' and assign an appropriate number. Enter 'None' in case you want to see all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                    n  perc\n",
      "  ============================  ===== =====\n",
      "               Total elements:  2,930      \n",
      "              Unique elements:     28      \n",
      "\n",
      "  Top-10 (type: 'str')              n  perc\n",
      "  ============================  =====  =====\n",
      "                         NAmes    443  15.1%\n",
      "                       CollgCr    267   9.1%\n",
      "                       OldTown    239   8.2%\n",
      "                       Edwards    194   6.6%\n",
      "                       Somerst    182   6.2%\n",
      "                       NridgHt    166   5.7%\n",
      "                       Gilbert    165   5.6%\n",
      "                        Sawyer    151   5.2%\n",
      "                        NWAmes    131   4.5%\n",
      "                       SawyerW    125   4.3%\n",
      "                           ...    ...    ...\n",
      "  ----------------------------  -----  -----\n",
      "                         TOTAL  2,930   100%\n"
     ]
    }
   ],
   "source": [
    "f_info(df_orig.Neighborhood)\n",
    "#f_info(df_orig.Neighborhood, n_top=None, b_show_plot=True)\n",
    "#f_info(df_orig['Pool QC'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Impute missing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would move the imputation exercise till after the train/test split. What is the problem of imputing the data before the train/test split?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info()` method and the `f_info()` function in the previous exercise informed us that there are several missing values in the dataset. These need to be tackled before we can proceed with the remainder of the analysis, in particular before calculating correlations and applying machine learning models. There are many ways to impute missing values. Here, we impute missing values as follows:\n",
    "\n",
    "a. Impute the numerical variables with the median value of the available data\n",
    "\n",
    "b1. Impute the categorical variables with the label \"other\"\n",
    "\n",
    "b2. Alternatively, impute the categorical variables with the mode (most frequent value) of the available data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Impute the numerical variables with the median value of the available data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace NA's in numerical variables with the median value in each variable, resp. As expected, we observe that the median values of the updated columns have not changed compared to the original data. Besides, we confirm there are no empty cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median values in original numerical data (first five variables):\n",
      "Order           1.47e+03\n",
      "PID             5.35e+08\n",
      "MS SubClass     5.00e+01\n",
      "Lot Frontage    6.80e+01\n",
      "Lot Area        9.44e+03\n",
      "dtype: float64\n",
      "\n",
      "Median values in imputed numerical data (first five variables):\n",
      "Order           1.47e+03\n",
      "PID             5.35e+08\n",
      "MS SubClass     5.00e+01\n",
      "Lot Frontage    6.80e+01\n",
      "Lot Area        9.44e+03\n",
      "dtype: float64\n",
      "\n",
      "Number of missing data in imputed data: 0\n"
     ]
    }
   ],
   "source": [
    "df_num_imputed = df_num_orig.replace(np.nan, df_num_orig.median())\n",
    "\n",
    "print(\"Median values in original numerical data (first five variables):\")\n",
    "print(df_num_orig.median().head(5))\n",
    "\n",
    "print(\"\\nMedian values in imputed numerical data (first five variables):\")\n",
    "print(df_num_imputed.median().head(5))\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\\nNumber of missing data in imputed data: \"\n",
    "    f\"{df_num_imputed.isna().sum().sum()}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b1. Impute the categorical variables with the label \"other\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will replace NA's in the columns with categorical data. Besides `replace()` [(ref)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html), we can also make use of `fillna()` [(ref)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) to replace NA's by an alternative value.\n",
    "\n",
    "It is good practice to define a variable in case you use that variable in more than one place and/or in case you expect to change the value of the variable at later stage. This way you can define the variable, e.g., at the top of your script so it can be changed in one location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_replace_by = \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace using replace():\n",
    "df_cat_imputed     = df_cat_orig.replace(np.nan, c_replace_by)\n",
    "\n",
    "# Replace using fillna():\n",
    "df_cat_imputed_alt = df_cat_orig.fillna(c_replace_by)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as expected there are no empty cells in either of the two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    df_cat_imputed.isna().sum().sum(),\n",
    "    df_cat_imputed_alt.isna().sum().sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the replacement for a given categorical variable (`c_col`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the original data:\n",
      "Empty:   2917\n",
      "'other': 0\n",
      "\n",
      "Number of missing values in the data imputed using 'replace()':\n",
      "Empty:   0\n",
      "'other': 2917\n",
      "\n",
      "Number of missing values in the data imputed using 'fillna()':\n",
      "Empty:   0\n",
      "'other': 2917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define variable name to verify the imputations we made.\n",
    "c_col = 'Pool QC'\n",
    "\n",
    "# How many empty cells and 'c_replace_by' exist in the original data?\n",
    "print(\n",
    "    \"Number of missing values in the original data:\\n\"\n",
    "    f\"Empty:   {sum(df_cat_orig[c_col].isna())}\\n\"\n",
    "    f\"'{c_replace_by}': {df_cat_orig[c_col].tolist().count(c_replace_by)}\\n\"\n",
    ")\n",
    "\n",
    "# How many empty cells and 'c_replace_by' exist in the imputed data - using '.replace'?\n",
    "print(\n",
    "    \"Number of missing values in the data imputed using 'replace()':\\n\"\n",
    "    f\"Empty:   {sum(df_cat_imputed[c_col].isna())}\\n\"\n",
    "    f\"'{c_replace_by}': {df_cat_imputed[c_col].tolist().count(c_replace_by)}\\n\"\n",
    ")\n",
    "\n",
    "# # How many NA and 'c_replace_by' exist in the updated data - using '.fillna':\n",
    "print(\n",
    "    \"Number of missing values in the data imputed using 'fillna()':\\n\"\n",
    "    f\"Empty:   {sum(df_cat_imputed_alt[c_col].isna())}\\n\"\n",
    "    f\"'{c_replace_by}': {df_cat_imputed_alt[c_col].tolist().count(c_replace_by)}\\n\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b2. Alternatively, impute the categorical variables with the mode (most frequent value) of the available data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to replace NA's by the most frequently occurring value in each variable. How would we go about this? See also Python Explainer `Mode`.\n",
    "\n",
    "Let's work towards to answer.. To get the mode of each column in a Pandas Data frame, we simply use the `mode()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>Land Slope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition 1</th>\n",
       "      <th>Condition 2</th>\n",
       "      <th>Bldg Type</th>\n",
       "      <th>House Style</th>\n",
       "      <th>Roof Style</th>\n",
       "      <th>Roof Matl</th>\n",
       "      <th>Exterior 1st</th>\n",
       "      <th>Exterior 2nd</th>\n",
       "      <th>Mas Vnr Type</th>\n",
       "      <th>Exter Qual</th>\n",
       "      <th>Exter Cond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Bsmt Cond</th>\n",
       "      <th>Bsmt Exposure</th>\n",
       "      <th>BsmtFin Type 1</th>\n",
       "      <th>BsmtFin Type 2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Heating QC</th>\n",
       "      <th>Central Air</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>Kitchen Qual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplace Qu</th>\n",
       "      <th>Garage Type</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Garage Qual</th>\n",
       "      <th>Garage Cond</th>\n",
       "      <th>Paved Drive</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Ex</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MS Zoning Street Alley Lot Shape Land Contour Utilities Lot Config  \\\n",
       "0        RL   Pave  Grvl       Reg          Lvl    AllPub     Inside   \n",
       "1       NaN    NaN   NaN       NaN          NaN       NaN        NaN   \n",
       "\n",
       "  Land Slope Neighborhood Condition 1 Condition 2 Bldg Type House Style  \\\n",
       "0        Gtl        NAmes        Norm        Norm      1Fam      1Story   \n",
       "1        NaN          NaN         NaN         NaN       NaN         NaN   \n",
       "\n",
       "  Roof Style Roof Matl Exterior 1st Exterior 2nd Mas Vnr Type Exter Qual  \\\n",
       "0      Gable   CompShg      VinylSd      VinylSd      BrkFace         TA   \n",
       "1        NaN       NaN          NaN          NaN          NaN        NaN   \n",
       "\n",
       "  Exter Cond Foundation Bsmt Qual Bsmt Cond Bsmt Exposure BsmtFin Type 1  \\\n",
       "0         TA      PConc        TA        TA            No            GLQ   \n",
       "1        NaN        NaN       NaN       NaN           NaN            NaN   \n",
       "\n",
       "  BsmtFin Type 2 Heating Heating QC Central Air Electrical Kitchen Qual  \\\n",
       "0            Unf    GasA         Ex           Y      SBrkr           TA   \n",
       "1            NaN     NaN        NaN         NaN        NaN          NaN   \n",
       "\n",
       "  Functional Fireplace Qu Garage Type Garage Finish Garage Qual Garage Cond  \\\n",
       "0        Typ           Gd      Attchd           Unf          TA          TA   \n",
       "1        NaN          NaN         NaN           NaN         NaN         NaN   \n",
       "\n",
       "  Paved Drive Pool QC  Fence Misc Feature Sale Type Sale Condition  \n",
       "0           Y      Ex  MnPrv         Shed       WD          Normal  \n",
       "1         NaN      Gd    NaN          NaN       NaN            NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_orig.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the data frame have two rows? Tip, investigate the 'Pool QC' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                    n  perc\n",
      "  ============================  =====  =====\n",
      "               Total elements:  2,930       \n",
      "              Unique elements:      5       \n",
      "                    pd.isna():  2,917  99.6%\n",
      "\n",
      "  All items: (type: 'str')          n  perc\n",
      "  ============================  =====  =====\n",
      "                            NA   2917  99.6%\n",
      "                            Ex      4   0.1%\n",
      "                            Gd      4   0.1%\n",
      "                            TA      3   0.1%\n",
      "                            Fa      2   0.1%\n",
      "  ----------------------------  -----  -----\n",
      "                         TOTAL  2,930   100%\n"
     ]
    }
   ],
   "source": [
    "f_info(df_cat_orig['Pool QC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue.. We take the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MS Zoning             RL\n",
       "Street              Pave\n",
       "Alley               Grvl\n",
       "Lot Shape            Reg\n",
       "Land Contour         Lvl\n",
       "                   ...  \n",
       "Pool QC               Ex\n",
       "Fence              MnPrv\n",
       "Misc Feature        Shed\n",
       "Sale Type            WD \n",
       "Sale Condition    Normal\n",
       "Name: 0, Length: 43, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_orig.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we put it all together and assign the result to a new object `df_cat_imputed_mode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_imputed_mode = df_cat_orig.fillna(df_cat_orig.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the result.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                    n  perc\n",
      "  ============================  =====  =====\n",
      "               Total elements:  2,930       \n",
      "              Unique elements:      3       \n",
      "                    pd.isna():  2,732  93.2%\n",
      "\n",
      "  All items: (type: 'str')          n  perc\n",
      "  ============================  =====  =====\n",
      "                            NA   2732  93.2%\n",
      "                          Grvl    120   4.1%\n",
      "                          Pave     78   2.7%\n",
      "  ----------------------------  -----  -----\n",
      "                         TOTAL  2,930   100%\n"
     ]
    }
   ],
   "source": [
    "f_info(df_cat_orig['Alley'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                    n  perc\n",
      "  ============================  ===== =====\n",
      "               Total elements:  2,930      \n",
      "              Unique elements:      2      \n",
      "\n",
      "  All items: (type: 'str')          n  perc\n",
      "  ============================  =====  =====\n",
      "                          Grvl   2852  97.3%\n",
      "                          Pave     78   2.7%\n",
      "  ----------------------------  -----  -----\n",
      "                         TOTAL  2,930   100%\n"
     ]
    }
   ],
   "source": [
    "f_info(df_cat_imputed_mode['Alley'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use Python's build-in method `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      198\n",
       "unique       2\n",
       "top       Grvl\n",
       "freq       120\n",
       "Name: Alley, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_orig['Alley'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2930\n",
       "unique       2\n",
       "top       Grvl\n",
       "freq      2852\n",
       "Name: Alley, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_imputed_mode['Alley'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check that the numbers match.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2852"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2930-198)+120"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Concatenate the numerical and the categorical data into a single data frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we [concatenate](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) the two imputed data frames to create one new data frame without empty cells. What is the role of 'axis=1'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = pd.concat([df_cat_imputed_mode, df_num_imputed], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the original and updated data frames have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 82) (2930, 82)\n"
     ]
    }
   ],
   "source": [
    "print(df_imputed.shape, df_orig.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra - Optimize memory usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory taken by the original data frame is obtained by adding `memory_usage=\"deep\"` to the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   MS Zoning        2930 non-null   object \n",
      " 1   Street           2930 non-null   object \n",
      " 2   Alley            2930 non-null   object \n",
      " 3   Lot Shape        2930 non-null   object \n",
      " 4   Land Contour     2930 non-null   object \n",
      " 5   Utilities        2930 non-null   object \n",
      " 6   Lot Config       2930 non-null   object \n",
      " 7   Land Slope       2930 non-null   object \n",
      " 8   Neighborhood     2930 non-null   object \n",
      " 9   Condition 1      2930 non-null   object \n",
      " 10  Condition 2      2930 non-null   object \n",
      " 11  Bldg Type        2930 non-null   object \n",
      " 12  House Style      2930 non-null   object \n",
      " 13  Roof Style       2930 non-null   object \n",
      " 14  Roof Matl        2930 non-null   object \n",
      " 15  Exterior 1st     2930 non-null   object \n",
      " 16  Exterior 2nd     2930 non-null   object \n",
      " 17  Mas Vnr Type     2930 non-null   object \n",
      " 18  Exter Qual       2930 non-null   object \n",
      " 19  Exter Cond       2930 non-null   object \n",
      " 20  Foundation       2930 non-null   object \n",
      " 21  Bsmt Qual        2930 non-null   object \n",
      " 22  Bsmt Cond        2930 non-null   object \n",
      " 23  Bsmt Exposure    2930 non-null   object \n",
      " 24  BsmtFin Type 1   2930 non-null   object \n",
      " 25  BsmtFin Type 2   2930 non-null   object \n",
      " 26  Heating          2930 non-null   object \n",
      " 27  Heating QC       2930 non-null   object \n",
      " 28  Central Air      2930 non-null   object \n",
      " 29  Electrical       2930 non-null   object \n",
      " 30  Kitchen Qual     2930 non-null   object \n",
      " 31  Functional       2930 non-null   object \n",
      " 32  Fireplace Qu     2930 non-null   object \n",
      " 33  Garage Type      2930 non-null   object \n",
      " 34  Garage Finish    2930 non-null   object \n",
      " 35  Garage Qual      2930 non-null   object \n",
      " 36  Garage Cond      2930 non-null   object \n",
      " 37  Paved Drive      2930 non-null   object \n",
      " 38  Pool QC          2930 non-null   object \n",
      " 39  Fence            2930 non-null   object \n",
      " 40  Misc Feature     2930 non-null   object \n",
      " 41  Sale Type        2930 non-null   object \n",
      " 42  Sale Condition   2930 non-null   object \n",
      " 43  Order            2930 non-null   int64  \n",
      " 44  PID              2930 non-null   int64  \n",
      " 45  MS SubClass      2930 non-null   int64  \n",
      " 46  Lot Frontage     2930 non-null   float64\n",
      " 47  Lot Area         2930 non-null   int64  \n",
      " 48  Overall Qual     2930 non-null   int64  \n",
      " 49  Overall Cond     2930 non-null   int64  \n",
      " 50  Year Built       2930 non-null   int64  \n",
      " 51  Year Remod/Add   2930 non-null   int64  \n",
      " 52  Mas Vnr Area     2930 non-null   float64\n",
      " 53  BsmtFin SF 1     2930 non-null   float64\n",
      " 54  BsmtFin SF 2     2930 non-null   float64\n",
      " 55  Bsmt Unf SF      2930 non-null   float64\n",
      " 56  Total Bsmt SF    2930 non-null   float64\n",
      " 57  1st Flr SF       2930 non-null   int64  \n",
      " 58  2nd Flr SF       2930 non-null   int64  \n",
      " 59  Low Qual Fin SF  2930 non-null   int64  \n",
      " 60  Gr Liv Area      2930 non-null   int64  \n",
      " 61  Bsmt Full Bath   2930 non-null   float64\n",
      " 62  Bsmt Half Bath   2930 non-null   float64\n",
      " 63  Full Bath        2930 non-null   int64  \n",
      " 64  Half Bath        2930 non-null   int64  \n",
      " 65  Bedroom AbvGr    2930 non-null   int64  \n",
      " 66  Kitchen AbvGr    2930 non-null   int64  \n",
      " 67  TotRms AbvGrd    2930 non-null   int64  \n",
      " 68  Fireplaces       2930 non-null   int64  \n",
      " 69  Garage Yr Blt    2930 non-null   float64\n",
      " 70  Garage Cars      2930 non-null   float64\n",
      " 71  Garage Area      2930 non-null   float64\n",
      " 72  Wood Deck SF     2930 non-null   int64  \n",
      " 73  Open Porch SF    2930 non-null   int64  \n",
      " 74  Enclosed Porch   2930 non-null   int64  \n",
      " 75  3Ssn Porch       2930 non-null   int64  \n",
      " 76  Screen Porch     2930 non-null   int64  \n",
      " 77  Pool Area        2930 non-null   int64  \n",
      " 78  Misc Val         2930 non-null   int64  \n",
      " 79  Mo Sold          2930 non-null   int64  \n",
      " 80  Yr Sold          2930 non-null   int64  \n",
      " 81  SalePrice        2930 non-null   int64  \n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_imputed.info(memory_usage=\"deep\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making any changes, we make a copy of df_imputed, so, we can investigate the effect of memory optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df_imputed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the categorical columns to `category` type columns using the [`astype()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_df_cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[l_df_cat_names] = df_updated[l_df_cat_names].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `integer` and `float` variables are converted to their smallest possible *unsigned* versions by using [`pd.to_numeric(arg, downcast=...)`](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html#pandas.to_numeric).\n",
    "\n",
    "The `zip()` function allows for a pythonic solution, where alternatively you would iterate through a list of indices and use each index to select values from two or more lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for old, new in zip(['integer', 'float'], ['unsigned', 'float']):\n",
    "\n",
    "    for col in df_updated.select_dtypes(include=old).columns:\n",
    "        \n",
    "        df_updated[col] = pd.to_numeric(df_updated[col], downcast=new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this brings in terms of the size of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   MS Zoning        2930 non-null   category\n",
      " 1   Street           2930 non-null   category\n",
      " 2   Alley            2930 non-null   category\n",
      " 3   Lot Shape        2930 non-null   category\n",
      " 4   Land Contour     2930 non-null   category\n",
      " 5   Utilities        2930 non-null   category\n",
      " 6   Lot Config       2930 non-null   category\n",
      " 7   Land Slope       2930 non-null   category\n",
      " 8   Neighborhood     2930 non-null   category\n",
      " 9   Condition 1      2930 non-null   category\n",
      " 10  Condition 2      2930 non-null   category\n",
      " 11  Bldg Type        2930 non-null   category\n",
      " 12  House Style      2930 non-null   category\n",
      " 13  Roof Style       2930 non-null   category\n",
      " 14  Roof Matl        2930 non-null   category\n",
      " 15  Exterior 1st     2930 non-null   category\n",
      " 16  Exterior 2nd     2930 non-null   category\n",
      " 17  Mas Vnr Type     2930 non-null   category\n",
      " 18  Exter Qual       2930 non-null   category\n",
      " 19  Exter Cond       2930 non-null   category\n",
      " 20  Foundation       2930 non-null   category\n",
      " 21  Bsmt Qual        2930 non-null   category\n",
      " 22  Bsmt Cond        2930 non-null   category\n",
      " 23  Bsmt Exposure    2930 non-null   category\n",
      " 24  BsmtFin Type 1   2930 non-null   category\n",
      " 25  BsmtFin Type 2   2930 non-null   category\n",
      " 26  Heating          2930 non-null   category\n",
      " 27  Heating QC       2930 non-null   category\n",
      " 28  Central Air      2930 non-null   category\n",
      " 29  Electrical       2930 non-null   category\n",
      " 30  Kitchen Qual     2930 non-null   category\n",
      " 31  Functional       2930 non-null   category\n",
      " 32  Fireplace Qu     2930 non-null   category\n",
      " 33  Garage Type      2930 non-null   category\n",
      " 34  Garage Finish    2930 non-null   category\n",
      " 35  Garage Qual      2930 non-null   category\n",
      " 36  Garage Cond      2930 non-null   category\n",
      " 37  Paved Drive      2930 non-null   category\n",
      " 38  Pool QC          2930 non-null   category\n",
      " 39  Fence            2930 non-null   category\n",
      " 40  Misc Feature     2930 non-null   category\n",
      " 41  Sale Type        2930 non-null   category\n",
      " 42  Sale Condition   2930 non-null   category\n",
      " 43  Order            2930 non-null   uint16  \n",
      " 44  PID              2930 non-null   uint32  \n",
      " 45  MS SubClass      2930 non-null   uint8   \n",
      " 46  Lot Frontage     2930 non-null   float32 \n",
      " 47  Lot Area         2930 non-null   uint32  \n",
      " 48  Overall Qual     2930 non-null   uint8   \n",
      " 49  Overall Cond     2930 non-null   uint8   \n",
      " 50  Year Built       2930 non-null   uint16  \n",
      " 51  Year Remod/Add   2930 non-null   uint16  \n",
      " 52  Mas Vnr Area     2930 non-null   float32 \n",
      " 53  BsmtFin SF 1     2930 non-null   float32 \n",
      " 54  BsmtFin SF 2     2930 non-null   float32 \n",
      " 55  Bsmt Unf SF      2930 non-null   float32 \n",
      " 56  Total Bsmt SF    2930 non-null   float32 \n",
      " 57  1st Flr SF       2930 non-null   uint16  \n",
      " 58  2nd Flr SF       2930 non-null   uint16  \n",
      " 59  Low Qual Fin SF  2930 non-null   uint16  \n",
      " 60  Gr Liv Area      2930 non-null   uint16  \n",
      " 61  Bsmt Full Bath   2930 non-null   float32 \n",
      " 62  Bsmt Half Bath   2930 non-null   float32 \n",
      " 63  Full Bath        2930 non-null   uint8   \n",
      " 64  Half Bath        2930 non-null   uint8   \n",
      " 65  Bedroom AbvGr    2930 non-null   uint8   \n",
      " 66  Kitchen AbvGr    2930 non-null   uint8   \n",
      " 67  TotRms AbvGrd    2930 non-null   uint8   \n",
      " 68  Fireplaces       2930 non-null   uint8   \n",
      " 69  Garage Yr Blt    2930 non-null   float32 \n",
      " 70  Garage Cars      2930 non-null   float32 \n",
      " 71  Garage Area      2930 non-null   float32 \n",
      " 72  Wood Deck SF     2930 non-null   uint16  \n",
      " 73  Open Porch SF    2930 non-null   uint16  \n",
      " 74  Enclosed Porch   2930 non-null   uint16  \n",
      " 75  3Ssn Porch       2930 non-null   uint16  \n",
      " 76  Screen Porch     2930 non-null   uint16  \n",
      " 77  Pool Area        2930 non-null   uint16  \n",
      " 78  Misc Val         2930 non-null   uint16  \n",
      " 79  Mo Sold          2930 non-null   uint8   \n",
      " 80  Yr Sold          2930 non-null   uint16  \n",
      " 81  SalePrice        2930 non-null   uint32  \n",
      "dtypes: category(43), float32(11), uint16(15), uint32(3), uint8(10)\n",
      "memory usage: 423.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_updated.info(memory_usage=\"deep\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much did we reduce the memory need? See also [\"How To Get The Memory Usage of Pandas Dataframe?\"](https://cmdlinetips.com/2020/03/memory-usage-of-pandas-dataframe/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original data frame              : 7.8 MB.\n",
      "Size of imputed data frame               : 8.2 MB.\n",
      "Size of imputed and downcasted data frame: 0.41 MB.\n",
      "Reduced original data frame by factor of : 19\n"
     ]
    }
   ],
   "source": [
    "par1 = df_orig.memory_usage(deep=True).sum()/1024/1024\n",
    "par2 = df_imputed.memory_usage(deep=True).sum()/1024/1024\n",
    "par3 = df_updated.memory_usage(deep=True).sum()/1024/1024\n",
    "\n",
    "print(f\"Size of original data frame              : {round(par1, 1)} MB.\")\n",
    "print(f\"Size of imputed data frame               : {round(par2, 1)} MB.\")\n",
    "print(f\"Size of imputed and downcasted data frame: {round(par3, 2)} MB.\")\n",
    "print(f\"Reduced original data frame by factor of : {round(par1/par3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original Pandas series              : 0.18 MB.\n",
      "Size of imputed Pandas series               : 0.18 MB.\n",
      "Size of imputed and downcasted Pandas series: 0.006 MB.\n",
      "Reduced original data frame by factor of    : 31\n"
     ]
    }
   ],
   "source": [
    "par1 = df_orig1['Neighborhood'].memory_usage(deep=True)/1024/1024\n",
    "par2 = df_imputed['Neighborhood'].memory_usage(deep=True)/1024/1024\n",
    "par3 = df_updated['Neighborhood'].memory_usage(deep=True)/1024/1024\n",
    "\n",
    "print(f\"Size of original Pandas series              : {round(par1, 2)} MB.\")\n",
    "print(f\"Size of imputed Pandas series               : {round(par2, 2)} MB.\")\n",
    "print(f\"Size of imputed and downcasted Pandas series: {round(par3, 3)} MB.\")\n",
    "print(f\"Reduced original data frame by factor of    : {round(par1/par3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this case the original dataset has relatively small size (7.8 MB), and we can easily get away with not downcasting the data. If anything gets beyond hundreds of MBs in memory, a factor 20-30 is certainly helpfull! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Explore the outcome variable (`SalePrice`) and how it correlates to other variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding (continued)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the outcome variable 'SalePrice', representing the sale price of the homes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Conduct descriptive/summary statistics on the Y variable (mean, median, std, range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use the SalePrice data multiple times in this notebook, we assign it (Pandas Series) to an object, which we call, `ps_y`. What does it mean for the shape of the distribution that the mean exceeds the median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of sale price (Y):\n",
      "Mean:   180796.1\n",
      "Median: 160000.0\n",
      "Std:    79886.7\n",
      "Range:  12789 till 755000\n"
     ]
    }
   ],
   "source": [
    "ps_y = df_updated['SalePrice']\n",
    "\n",
    "print(\"Summary statistics of sale price (Y):\")\n",
    "print(f\"Mean:   {round(ps_y.mean(), 1)}\")\n",
    "print(f\"Median: {round(ps_y.median(), 1)}\")\n",
    "print(f\"Std:    {round(ps_y.std(), 1)}\")\n",
    "print(f\"Range:  {ps_y.min()} till {ps_y.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Investigate how grand living area (numerical) relate to the Y variable. Tip: Use scatter plots (hint: [`seaborn.scatterplot`](https://seaborn.pydata.org/generated/seaborn.scatterplot.html), [altair.scatter](https://altair-viz.github.io/gallery/scatter_tooltips.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Investigate how neighborhood (categorical) and grand living area (numerical) relate to the Y variable. Use, e.g., bar charts, scatter plots, and boxplots (hint: [`seaborn.histplot`](https://seaborn.pydata.org/generated/seaborn.histplot.html), [`seaborn.scatterplot`](https://seaborn.pydata.org/generated/seaborn.scatterplot.html), [`seaborn.boxplot`](https://seaborn.pydata.org/generated/seaborn.boxplot.html), [altair.histogram](https://altair-viz.github.io/gallery/simple_histogram.html), [altair.scatter](https://altair-viz.github.io/gallery/scatter_tooltips.html), [altair.boxplot](https://altair-viz.github.io/gallery/boxplot.html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we investigate how the `Neighborhood` variable - as example of a categorical variable - and `SalePrice` variable relate to each other. In the same way we investigate the relation between the `Gr Liv Area` - as example of a numerical variable - and the `SalePrice`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b1. Number of neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `f_neighborhood_order()` orders the neighborhoods by the median value of a given numerical variable (`c_col`) in the given data (`df_input`). In the example below, we order the neighborhoods by `SalePrice`. The result shows that MeadowV has the lowest median value for `SalePrice` and StoneBr has the highest.\n",
    "\n",
    "The function `describe()` showed that the `Neighborhood` variable consists of 28 distinct values. This is also observed when determining the length of `l_neighborhood_order_by_saleprice`. So, that's good.\n",
    "\n",
    "Functions specifically used in this notebook are given below. Functions used across projects are maintained in package 'utils_pieter'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# To sort the neighborhoods by the median of a given numerical column.\n",
    "# E.g., this function is useful in case you want to order the neighborhoods\n",
    "# by the median value of 'SalePrices', a numerical variable.\n",
    "def f_neighborhood_order(df_input, c_col):\n",
    "\n",
    "    # Error check - Is column 'c_col' numeric?\n",
    "    if(not is_numeric_dtype(df_input[c_col])):\n",
    "\n",
    "        print(f\"Column {c_col} is not numeric!\")\n",
    "        \n",
    "        return\n",
    " \n",
    "    v_neighborhood_order = (\n",
    "        df_input\n",
    "        .groupby(['Neighborhood'])[c_col]\n",
    "        .median()\n",
    "        .sort_values(ascending=True)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    return list(v_neighborhood_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_neighborhood_order_by_saleprice = f_neighborhood_order(df_input = df_updated, c_col = 'SalePrice')\n",
    "\n",
    "print(l_neighborhood_order_by_saleprice)\n",
    "print(len(l_neighborhood_order_by_saleprice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at the differences between neighborhoods, let's see how many houses have been sold in each neighborhood. Seaborn's `countplot()` function plots the frequency of the values in a given categorical variable, i.e., `Neighborhood` in the example below ([ref](https://seaborn.pydata.org/generated/seaborn.countplot.html)). Using `l_neighborhood_order_by_saleprice`, the neighborhoods along the x-axis are ordered by the median of the sale price in the concerned neigherhood. So, we have the expensive areas to the right and the less expensive areas to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    \n",
    "    data  = df_updated,\n",
    "    x     = \"Neighborhood\",\n",
    "    order = l_neighborhood_order_by_saleprice\n",
    ");\n",
    "\n",
    "plt.xticks(rotation=45);\n",
    "plt.xlabel(\"Neighborhood\")\n",
    "plt.ylabel(\"Number of houses\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b2. Distribution of Y variable per neighborhood (Pandas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the benefit of adding `bins` parameter? See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Explainer\n",
    "np.arange(0, max(ps_y), 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_y.hist(\n",
    "    \n",
    "    by      = df_updated['Neighborhood'],\n",
    "    figsize = (30,20),\n",
    "    xrot    = 25,\n",
    "    bins    = np.arange(0, max(ps_y), 20000)\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b3. Distribution of Y variable per neighborhood (Seaborn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FacetGrid()` function makes life a lot easier.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid.\n",
    "g = sns.FacetGrid(data=df_updated, col=\"Neighborhood\", col_wrap=5)\n",
    "\n",
    "# Apply 'sns.histplot' to each grid element in g.\n",
    "g.map(sns.histplot, 'SalePrice');\n",
    "\n",
    "# Set x-axis ticks.\n",
    "g.set(xticks=[300000, 600000])\n",
    "\n",
    "# Manage white space surrounding the subplots.\n",
    "plt.subplots_adjust(    \n",
    "    hspace=0.3,\n",
    "    wspace=0.1\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b4. Scatterplot of Y variable and Grand Living Area (Seaborn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows how seaborn's `scatterplot()` function can directly make use of a categorical variable - `Neighborhood` in this case - to give data points different colors ([ref](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)). Regarding the legend position ([ref](https://www.statology.org/seaborn-legend-position/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_x=\"Gr Liv Area\"\n",
    "#c_x=\"1st Flr SF\"\n",
    "\n",
    "sns.scatterplot(\n",
    "    \n",
    "    data = df_updated,  # Before removing homes with high 'Gr Liv Area'.\n",
    "    #data = df_reduced, # After removing homes with high 'Gr Liv Area'.\n",
    "    x    = c_x,\n",
    "    y    = 'SalePrice',\n",
    "    hue  = 'Neighborhood'\n",
    ")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.1));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the length of the legend and the broad spectrum of colours, it is clear that this approach is not very informative. Or, we remove the 'hue' parameter. In the next plot we make use of `FacetGrid()` again. Reducing the alpha helps to show the distribution of the data and whether there really is a trend or not. By default - with alpha equal to 1 - ten overlapping data points give the same impression as one data point.\n",
    "\n",
    "The figure below suggests that houses sold in the more expensive areas - like 'NridgHt' and 'StoneBr' - have a higher sale price per square feet of living area, than in the less expensive areas, like 'MeadowV' and 'NPkVill'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid.\n",
    "g = sns.FacetGrid(\n",
    "    \n",
    "    data     = df_updated,\n",
    "    col      = \"Neighborhood\",\n",
    "    col_wrap = 5\n",
    ")\n",
    "\n",
    "# Apply the sns.histplot to each grid element in g.\n",
    "g.map(sns.scatterplot, c_x, 'SalePrice', alpha = 0.2)\n",
    "g.set_xticklabels(rotation=30)\n",
    "\n",
    "# Manage white space surrounding the subplots.\n",
    "plt.subplots_adjust(\n",
    "    \n",
    "    hspace = 0.5,\n",
    "    wspace = 1\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's `relplot()` function makes it even easier to plot relations between two variables grouped by another variable and colored by yet another variable ([ref](https://seaborn.pydata.org/tutorial/relational.html)).\n",
    "\n",
    "Houses with more cars in their garages tend to be bigger and have a higher sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    \n",
    "    data     = df_updated,\n",
    "    x        = c_x,\n",
    "    y        = \"SalePrice\",\n",
    "    col      = \"Neighborhood\",\n",
    "    hue      = \"Garage Cars\",\n",
    "    palette  = \"rocket_r\",\n",
    "    col_wrap = 5\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "einde"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b5. Boxplots of Y variable and Neighborhood (Seaborn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots can be made with Seaborn's boxplot() function easily ([ref](https://seaborn.pydata.org/generated/seaborn.boxplot.html)). In the example below, the distribution of the sale price is given for each neighborhood. Note, the neighborhoods are ordered by `l_neighborhood_order_by_saleprice`, the median value - the horizontal line in the middle of the IQR box - goes up steadily from left to right.\n",
    "\n",
    "Alternatively, we can investigate another continuous variable, like `Gr Liv Area` (grand living area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_col = 'SalePrice'\n",
    "#c_col = 'Gr Liv Area'\n",
    "\n",
    "sns.boxplot(\n",
    "    \n",
    "    data  = df_updated,\n",
    "    x     = 'Neighborhood',\n",
    "    y     = c_col,\n",
    "    order = l_neighborhood_order_by_saleprice);\n",
    "\n",
    "plt.xticks(rotation = 25);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b6. 2D Histogram of Y variable and Neighborhood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's `histplot()` function allows plotting of 2D histograms, when - besides a value for `x` - also a value for `y` is provided ([ref](https://seaborn.pydata.org/generated/seaborn.histplot.html)). The way to *read* this plot is to imagine you view a stack of histograms from above. One histogram for each neighborhood. The higher the frequency the darker the square.\n",
    "\n",
    "The histplot does not have the option to include an `order` parameter. So, to order the neighborhoods on the y-axis by those in `l_neighborhood_order_by_saleprice`, we use Pandas' `cat.categories` method ([ref](https://pandas.pydata.org/docs/user_guide/categorical.html#operations), [ref](https://stackoverflow.com/questions/38023881/pandas-change-the-order-of-levels-of-factor-type-object))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.Neighborhood = df_updated.Neighborhood.cat.reorder_categories(l_neighborhood_order_by_saleprice, ordered=True)\n",
    "#l_neighborhood_order_by_saleprice\n",
    "\n",
    "# Alternatively, create a new data frame:\n",
    "#df_temp = df_updated.copy()\n",
    "#df_temp['Neighborhood'] = pd.Categorical(df_temp['Neighborhood'], l_neighborhood_order_by_saleprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    \n",
    "    data   = df_updated, #df_temp\n",
    "\n",
    "    #x      = \"Gr Liv Area\",\n",
    "    x     = \"SalePrice\",\n",
    "\n",
    "    y      = 'Neighborhood'\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b7. ECDF's of Y variable and Neighborhood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different way of looking at distributions is by plotting the cumulative counts using the empirical cumulative distribution function ([ECDF](https://seaborn.pydata.org/tutorial/distributions.html)). This plot draws a monotonically-increasing curve through each datapoint such that the height of the curve reflects the proportion of observations with a smaller value. So, a steeper line means a narrower distribution. The ECDF plot has two key advantages compared to traditional histogram:\n",
    "\n",
    "1. Unlike the histogram or KDE, it directly represents each datapoint. That means there is no bin size or smoothing parameter to consider, and\n",
    "\n",
    "2. since ECDF curves are represented by monotonically increasing lined, it is well-suited for comparing multiple distributions.\n",
    "\n",
    "In the example below, we plot the three least expensive neighborhoods. We observe that 'BrDale' has a narrower `SalePrice` distribution than 'IDOTRR' has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Neighborhood is a categorical variable, the legend in each of the\n",
    "# four graph will show all neighborhoods,  even though only a subset is shown.\n",
    "# The solution is to bring the variable back to a string. Not to interfere\n",
    "# with the original data frame (df), we create a new variable.\n",
    "df_updated['Neighborhood_str'] = df_updated.Neighborhood.astype(str)\n",
    "\n",
    "sns.histplot(\n",
    "    \n",
    "    data        = df_updated[df_updated['Neighborhood_str'].isin(l_neighborhood_order_by_saleprice[0:3])],\n",
    "    x           = \"SalePrice\",\n",
    "    hue         = \"Neighborhood_str\",\n",
    "    element     = \"step\",\n",
    "    fill        = False,\n",
    "    cumulative  = True,\n",
    "    stat        = \"density\",\n",
    "    common_norm = False,\n",
    "    legend      = True\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this for all neighborhoods and group them by median sale price. We observe that the more expensive neighborhoods have a wider distribution in sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the canvas of the subplots.\n",
    "plt.subplots(\n",
    "    \n",
    "    nrows   = 2,\n",
    "    ncols   = 2,\n",
    "    figsize = (20,10)\n",
    ")\n",
    "\n",
    "\n",
    "# In the first iteration i is equal to 1 and we plot the ECDF plot for the\n",
    "# first seven neighborhoods in l_neighborhood_order_by_saleprice.\n",
    "for n_i in range(1, 5):\n",
    "\n",
    "    # Go to the i-th subplot.\n",
    "    plt.subplot(2, 2, n_i)\n",
    "\n",
    "    sns.histplot(\n",
    "        \n",
    "        data        = df_updated[df_updated['Neighborhood_str'].isin(l_neighborhood_order_by_saleprice[(n_i-1)*7: n_i*7])],\n",
    "        x           = \"SalePrice\",\n",
    "        hue         = \"Neighborhood_str\",\n",
    "        element     = \"step\", \n",
    "        fill        = False,\n",
    "        cumulative  = True,\n",
    "        stat        = \"density\",\n",
    "        common_norm = False,\n",
    "        legend      = True,\n",
    "        binrange    = (0, max(ps_y))\n",
    "    )\n",
    "\n",
    "    plt.xticks(rotation=15);\n",
    "\n",
    "\n",
    "# Manage white space surrounding the subplots.\n",
    "plt.subplots_adjust(\n",
    "\n",
    "    left   = None,\n",
    "    bottom = None,\n",
    "    right  = None,\n",
    "    top    = None,\n",
    "    wspace = None,\n",
    "    hspace = 0.4\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove variable `Neighborhood_str`, since we no longer need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df_updated.drop('Neighborhood_str', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Visualize the distribution of the Y variable. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, data distributions are plotted using histograms. The bin width or the number of bins are a means to steer the granularity of the histogram. What is the downside of having too few and of having too many bins?\n",
    "\n",
    "To make it easier to investigate the effect of the number of bins, we define an object `n_bins`, assign a value to it, and use it with the argument `bins` in the plot functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1. Visualize the distribution of the Y variable - Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas `hist()` function is a quick way to obtain a histogram, by simply appending `.hist()` to a Pandas Series, or to a Pandas Data Frame and specify the column. All three examples below give the same result.\n",
    "\n",
    "1. How is the third one slightly different?\n",
    "\n",
    "2. You can see the effect of the ';'?\n",
    "\n",
    "3. What do observe in the shape of the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "df_updated['SalePrice'].hist(bins = n_bins);\n",
    "\n",
    "# Option 2\n",
    "#ps_y.hist(bins = n_bins);\n",
    "\n",
    "# Option 3\n",
    "#df_updated.hist(column = 'SalePrice', bins = n_bins);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2. Visualize the distribution of the Y variable - Using Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Seaborn` is a Python data visualization library based on matplotlib ([ref](https://seaborn.pydata.org/index.html)). Below an example using `histplot()` ([ref](https://seaborn.pydata.org/generated/seaborn.histplot.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_updated, x=\"SalePrice\", bins=n_bins);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to plot multiple distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in ['SalePrice', 'Year Built', '2nd Flr SF']:\n",
    "#     ax = sns.histplot(data=df_updated, x=x, bins=n_bins)\n",
    "#     plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3. Visualize the distribution of the Y variable - Estimate number of bins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graphs above we assumed a bin size set by `n_bins`. Given the distribution of the observed data we can estimate an optimal bin width using the [Freedman–Diaconis rule](https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule):\n",
    "\n",
    "bin width = 2 * IQR(`x`) / `n`^(1/3)\n",
    "\n",
    "where, IQR is the InterQuartile Range of the observed data `x`, and `n` is total number of observations in the data. The number of bins can be derived from the bin width and the range. \n",
    "\n",
    "For `SalePrice` we arrive at 63 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IQR is equal to the difference between the 75th and 25th percentiles.\n",
    "n_q25, n_q75 = np.percentile(ps_y, q = [25,75])\n",
    "\n",
    "n_IQR = n_q75 - n_q25\n",
    "\n",
    "# The bin width is calculated from the Freedman-Diaconis rule, see above.\n",
    "n_bin_width = 2 * n_IQR / (len(ps_y)**(1/3))\n",
    "\n",
    "# The number of bins easily follows from the range and the bin width.\n",
    "n_bins    = int((max(ps_y) - min(ps_y))/n_bin_width)\n",
    "\n",
    "print(f\"IQR:                              {n_IQR:,.0f}\")\n",
    "print(f\"Freedman–Diaconis bin width:      {round(n_bin_width):,.0f}\")\n",
    "print(f\"Freedman–Diaconis number of bins: {n_bins}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation (continued)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Assess the distribution of `SalePrice` in the previous exercise. What do you observe? Log-transform the outcome variable. What does it mean for the performance of the prediction model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the `SalePrice` distribution is skewed to the right. This causes the more expensive homes to 'pull' the predictions to higher values. To solve this we apply log transformation making the distribution more like a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create 'log' brother of ps_y.\n",
    "ps_y_log = np.log(ps_y)\n",
    "\n",
    "# Add ps_y_log to df_updated.\n",
    "df_updated['SalePrice_log'] = ps_y_log\n",
    "\n",
    "# Add 'SalePrice_log' to l_df_num_names.\n",
    "l_df_num_names.append('SalePrice_log')\n",
    "\n",
    "# Let's see the distribution ps_y_log. Looks much better!\n",
    "sns.histplot(data=ps_y_log, bins=n_bins);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e. Assess grand living area ('Gr Liv Area') for all houses in the previous exercise. What do you observe? Remove outliers. What does it mean for the scope of the prediction model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, we observe five houses that have an exceptionally large grand living area (`Gr Liv Area`), while three of them even have a relatively low sale price. We remove al houses with a grand living area exceeding 4,000 sq ft, and limit the scope of the model to houses having a grand living area up to 4,000 sq ft.\n",
    "\n",
    "We proceed the remainder of the analysis with `df_reduced`. It is good practice to assign a new variable name to the new object, as it has fewer rows, and being a significant change. This keeps `df_updated` available for later reference.  Of course, you cannot create new objects for each change, you will need to find the proper balance, between RAM and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper list. That is true in case the grand living area is smaller than 4000 sq ft,\n",
    "# and false in case it exceeds the threshold.\n",
    "l_temp         = df_updated['Gr Liv Area'] < 4000\n",
    "\n",
    "# Remove the concerned rows from the Pandas Data frames and from the Pandas Series.\n",
    "# In addition, we reset the index to prevent issues later on in case of merging data.\n",
    "df_reduced       = df_updated[l_temp].reset_index(drop=True)\n",
    "ps_y_log_reduced = ps_y_log[l_temp].reset_index(drop=True)\n",
    "df_num_reduced   = df_reduced.select_dtypes(include='number').reset_index(drop=True)\n",
    "df_cat_reduced   = df_reduced.select_dtypes(include='category').reset_index(drop=True)\n",
    "\n",
    "print(\"We proceed the analysis with:\")\n",
    "print(f\"{df_reduced.shape[0]} rows of the orginal {df_updated.shape[0]} rows in the dataset ({df_updated.shape[1]} columns), and,\")\n",
    "print(f\"{len(ps_y_log_reduced)} elements of the orginal {len(ps_y_log)} elements in the outcome variable.\")\n",
    "print(f\"While keeping {df_num_reduced.shape[1]} columns in numerical data and {df_cat_reduced.shape[1]} columns in categorical data.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding (continued)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Draw scatter plots between Y and each of the numerical variables (hint: use [`seaborn.pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we created a list object `l_df_num_names` to have all numerical variable names readily at hand. We will use this object to create scatterplots of each numerical variable against the SalePrice, using Seaborn's pairplot() function ([ref](https://seaborn.pydata.org/generated/seaborn.pairplot.html)). See also two Stackoverflow references ([ref1](https://stackoverflow.com/questions/31966494/compare-1-independent-vs-many-dependent-variables-using-seaborn-pairplot-in-an-h), [ref2](https://stackoverflow.com/questions/51400076/change-seaborn-pair-plot-figure-size/51403299))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l_df_num_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the number of rows that we need in the grid plot below, given the total number of panels and the number of panels per row, i.e., the number of columns in the grid plot (`n_col`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "n_col = 4\n",
    "n_num = len(l_df_num_names)\n",
    "n_row = math.ceil(n_num/n_col)\n",
    "\n",
    "# Number of numerical variables and number of rows, resp.\n",
    "print(n_num, n_row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's `pairplot()` function allows plotting of a row of scatter plots against the `SalePrice`, by setting `y_vars` equal to `SalePrice`. So, the `for` loop does not have to iterate through each element in `l_df_num_names`. In the example below, we plot `n_col` scatterplots in one row at the time. The setting `kind = 'reg'` adds the trendline, incl. its confidence interval. By default, `kind` is set to `scatter`. To get a better understanding of the data distribution it helps to set a low alpha value (i.e., marker transparancy). We observe that `Overall Quality` correlates well with `SalePrice`. The variable `Total Bsmt SF` also correlates well with `SalePrice`, while we also see some outliers that may cause the trendline to become shallower. Also with other 'SF' variables we observe outliers; something to keep in mind for Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the first iteration i is equal to one. This makes i_start equal to zero and i_stop equal to 4.\n",
    "# So, l_df_num_names[i_start:i_stop] results in the first four elements in l_df_num_names:\n",
    "# 'Order', 'PID', 'MS SubClass', and 'Lot Frontage'.\n",
    "\n",
    "# THIS STEP TAKES A LONGER TIME TO RUN THAN THE OTHERS.\n",
    "# SO, AS LONG AS I DO NOT NEED IT I LEAVE IT COMMENTED OUT.\n",
    "\n",
    "# for n_i in range(1, n_row + 1):\n",
    "\n",
    "#     i_start = (n_i-1) * 4\n",
    "#     i_stop  = n_i * 4\n",
    "\n",
    "#     if(i_stop > n_num):\n",
    "#         i_stop = n_num\n",
    "\n",
    "#     sns.pairplot(\n",
    "        \n",
    "#         data     = df_reduced, # Here, we can offer the complete data frame.\n",
    "#         y_vars   = ['SalePrice_log'],\n",
    "#         x_vars   = l_df_num_names[i_start:i_stop], # Here, we determine which variables are plotted.\n",
    "#         height   = 4,\n",
    "#         kind     = 'reg',\n",
    "#         plot_kws = {'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1}}\n",
    "#     );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g. Draw correlation plots to investigate the correlations between Y and each of the numerical variables (Hint: calculate the Pearson correlation coefficient and use [`seaborn.heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Pearson correlation coefficients between numerical variables and the outcome variable to understand how they correlate to each other. \n",
    "\n",
    "For correlation between categorical and numerical variables you can use ANOVA or the Point Biseral Test ([ref](https://www.tutorialspoint.com/correlation-between-categorical-and-continuous-variables)). For correlation between categorical variables you can use Cramer's V (symmetrical) or Theil's U (asymmetrical) ([ref](https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### g1. How is Pearson correlation coefficient calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pearson correlation coefficient (named after [Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson)) can be used to summarize the strength of the linear relationship between two numerical data samples. To understand the calculation of Pearson's correlation coefficient we reconstruct the calculation ([ref](https://machinelearningmastery.com/how-to-use-correlation-to-understand-the-relationship-between-variables/)). The coefficient is calculated as,\n",
    "\n",
    "Pearson's correlation coefficient = covariance(X, Y) / (stdv(X) * stdv(Y))\n",
    "\n",
    "We will work through an example where we calculate the correlation between the variables `SalePrice_log` and `Garage Cars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_variable      = 'Garage Cars'\n",
    "ps_variable     = df_reduced[c_variable]\n",
    "\n",
    "m_cov          = np.cov(ps_variable, ps_y_log_reduced)\n",
    "n_corr_cov_mat = round(m_cov[0,1] / (np.std(ps_y_log_reduced) * np.std(ps_variable)), 3)\n",
    "\n",
    "n_corr_pearson = round(pearsonr(ps_y_log_reduced, ps_variable)[0], 3)\n",
    "\n",
    "print(f\"Pearson correlation coefficient between variable '{c_variable}' and 'SalePrice_log', calculated using:\")\n",
    "\n",
    "print(f\"Covariance matrix-based formula: {n_corr_cov_mat}\")\n",
    "\n",
    "print(f\"Python built-in function:        {n_corr_pearson}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### g2. Calculate Pearson correlation coefficients between all numerical variables, incl the outcome variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed what `pearsonnr()` calculates, we apply it to all numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pearson_corr = []\n",
    "\n",
    "for i in range(0, n_num):\n",
    "\n",
    "  ps_variable = df_reduced[l_df_num_names[i]]\n",
    "  \n",
    "  l_pearson_corr.append(round(pearsonr(ps_y_log_reduced, ps_variable)[0], 2))\n",
    "\n",
    "  #m_cov = np.cov(ps_variable, ps_y_log_reduced)\n",
    "  #print(f\"{l_df_num_names[i]} : {round(m_cov[0,1] / (np.std(ps_y_log_reduced) * np.std(ps_variable)), 3)} / {round(pearsonr(ps_y_log_reduced, ps_variable)[0], 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `l_pearson_corr` contains the Pearson correlation coefficients between `SalePrice_log` and each numerical variable. We will use it to construct table sorted by the absolute value of the Pearson correlation coefficient (descending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start out by creating a data frame containing the Pearson correlation coefficients for each of the numerical variables.\n",
    "df_corr_table = pd.DataFrame({'name': l_df_num_names, 'corr': l_pearson_corr})\n",
    "\n",
    "# We add a variable to df_cov, the absolute value of the correlation coefficient.\n",
    "df_corr_table['corr_abs'] = abs(df_corr_table['corr'])\n",
    "\n",
    "# This is allows sorting of the variables by their correlation, irrespective of their sign.\n",
    "df_corr_table = df_corr_table.sort_values(by = 'corr_abs', ascending=False)\n",
    "\n",
    "# We show the ten numerical variables that have the highest correlation with the SalePrice_log.\n",
    "df_corr_table.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that `Overall Qual` has the highest correlation with `SalePrice_log`. What does this means in case of a model predicting `SalePrice_log`?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### g3. Plot correlation heatmap for all numerical variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmaps are a very useful way to visualize correlations ([ref](https://heartbeat.fritz.ai/seaborn-heatmaps-13-ways-to-customize-correlation-matrix-visualizations-f1c49c816f07)). To show the benefit of this approach, we plot a heatmap of all correlations among all numerical variables. We can identify which pairs have high and which have low correlation. Note, I made function `f_heatmap()` myself, see `i_general.py` to understand how it works. Feel free to copy paste the function into your notebook and check it out. By default, `f_heatmap()` shows the correlation coefficients in each box. Since the boxes are small, we set `b_annotate` to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_heatmap(    \n",
    "    df_input           = df_num_reduced,\n",
    "    v_variables_to_show = l_df_num_names,\n",
    "    b_annotate         = False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### g4. Plot correlation heatmap for Top-10 numerical variables having the heighest correlation with the outcome variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `df_corr_table` we can build a more focused heatmap showing the 10 numerical variables that have the highest correlation with `SalePrice_log`. Now, we include the correlation coefficients inside each box for more insights. You can change the font size of the annotation by assigning an argument to the parameter `n_font_size`.\n",
    "\n",
    "Besides the correlations with `SalePrice_log` it is now also more prominent that `Garage Area` and `Garage Cars` are highly correlated. What does this mean in terms of a linear regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_heatmap(    \n",
    "    df_input           = df_num_reduced,\n",
    "    v_variables_to_show = df_corr_table.head(10)['name'],\n",
    "    n_font_size        = 20\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### g5. Plot correlation heatmap for the numerical variables having 'SF' in the variable name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another way of subsetting the numerical variables. Suppose we want to select only those variables that contain 'SF' ('square feet'). To accomplish that we make use of a list comprehension ([RealPython](https://realpython.com/list-comprehension-python/)), see also the Python Explainer 'List Comprehensions'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df_num_names_sf = [x for x in l_df_num_names if \"SF\" in x]\n",
    "\n",
    "f_heatmap(\n",
    "    \n",
    "    df_input           = df_num_reduced,\n",
    "    v_variables_to_show = l_df_num_names_sf\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for demonstration purposes, list comprehensions also allow you to exclude certain strings, say '1st':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df_num_names_sf_wo_1st = [x for x in l_df_num_names if \"SF\" in x and \"1st\" not in x or x == 'SalePrice_log']\n",
    "\n",
    "f_heatmap(\n",
    "    \n",
    "    df_input           = df_num_reduced,\n",
    "    v_variables_to_show = l_df_num_names_sf_wo_1st\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Estimate a Linear Regression, a LASSO and a kNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into LASSO and kNN, we start out by exploring linear regression ([ref](https://towardsdatascience.com/linear-regression-in-python-9a1f5f000606))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Estimate a Linear Regression model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through a number of steps, starting with defining a list holding all numerical variables excluding `SalePrice` and `SalePrice_log`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a1. Define number of objects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we defined `df_num_reduced`, `df_cat_reduced`, `l_df_num_names`, and, `l_df_cat_names`. Now, we define object `l_df_X_names` as a subset of `l_df_num_names`, excluding `SalePrice`. Later we on, we define object `df_X` as a data frame containing alle numerical variables in the data, excluding `SalePrice`.\n",
    "\n",
    "We confirm that `l_df_num_names` and `l_df_cat_names` make up all variables in the original data and that `l_df_X_names` is two items shorter than `l_df_num_names`, excluding `SalePrice` and `SalePrice_log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df_X_names = [x for x in l_df_num_names if x not in ['SalePrice', 'SalePrice_log']]\n",
    "\n",
    "print(\n",
    "    len(l_df_num_names),\n",
    "    len(l_df_cat_names),\n",
    "    df_orig.shape[1],\n",
    "    len(l_df_X_names)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start out simple we build a linear model considering the Top-4 numerical variables with the highest correlation with `SalePrice_log`, the variable that we want to predict. By activating the concerned line we can assign a different list to `l_df_X_names_subset`.\n",
    "\n",
    "Depending on what scenario you want to follow, add/remove the '#'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_df_X_names_subset = ['Overall Qual']\n",
    "#l_df_X_names_subset = ['Overall Qual', 'Gr Liv Area']\n",
    "#l_df_X_names_subset = ['Overall Qual', 'Gr Liv Area', 'Garage Cars']\n",
    "l_df_X_names_subset = ['Overall Qual', 'Gr Liv Area', 'Total Bsmt SF']\n",
    "\n",
    "# Object 'df_X' is data frame containing all numerical variables in the data, except 'SalePrice' and 'SalePrice_log'.\n",
    "df_X = df_reduced[l_df_X_names]\n",
    "\n",
    "# Define object 'df_X_subset' as subset of df_X.\n",
    "df_X_subset = df_X[l_df_X_names_subset]\n",
    "\n",
    "print(df_X.shape, df_X_subset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra - Select best variables using SelectKBest**\n",
    "\n",
    "For regression tasks, we want to know which variables contain the most information i.e., are the best predictors. There are various techniques to answer this question ([ref](https://machinelearningmastery.com/variable-selection-for-regression-data/)). Above, we used the Pearson correlation coefficients and below we will use LASSO. Scikit-learn has various univariate variable selection methods for this purpose ([ref](https://scikit-learn.org/stable/modules/variable_selection.html)). As an example we will briefly demonstrate `SelectKBest()` ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.variable_selection.SelectKBest.html#sklearn.variable_selection.SelectKBest)). We observe that the same four variables are selected having the highest correlation with `SalePrice`. This should not be a surprise as variance - used for the f-statistic - and correlation are closely related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl.variable_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "from skl.variable_selection import SelectKBest, f_regression\n",
    "\n",
    "# For simplification we perform this on the original dataset. In practice, we would first\n",
    "# split the data and apply this function to the train data only.\n",
    "v_3best = (\n",
    "    \n",
    "    SelectKBest(f_regression, k = 4)\n",
    "    .fit(\n",
    "        df_X, ps_y_log_reduced\n",
    "    )\n",
    "    .get_support()\n",
    ")\n",
    "\n",
    "# Using get_support() we can filter out the three selected variables.\n",
    "# https://stackoverflow.com/questions/30837803/filter-list-using-boolean-index-arrays\n",
    "[x for x, b in zip(l_df_X_names, v_3best) if b]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a2. Visualize predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness we plot the concerned variables against `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    \n",
    "    data     = df_num_reduced,\n",
    "    x_vars   = l_df_X_names_subset,\n",
    "    y_vars   = 'SalePrice_log',\n",
    "    kind     = 'reg', # Turns on the trend line\n",
    "    height   = 7,\n",
    "    plot_kws = {'line_kws':{'color':'red'}, 'scatter_kws': {'alpha': 0.1}}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_heatmap(\n",
    "#     df_input           = df_num_reduced,\n",
    "#     v_variables_to_show = l_df_X_names_subset\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a3. Split the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the subset of the predictor data (`df_X_subset`) using `f_train_test_split()` that uses Scikit-Learn's `train_test_split()` function ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) and prints some stats, see `i_general.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data in train and test sets.\n",
    "df_X_train, df_X_test, ps_y_log_train, ps_y_log_test = f_train_test_split(df_X_subset, ps_y_log_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess the distribution of the response variable (`ps_y_log_reduced`) in both training and test data. For this, we construct a dataframe of the `ps_y_log_reduced` values and whether they are in the train or test set. Pandas' `set_axis()` function is used to provide the tag variable with a unique index, see also `s_temp2` and `s_temp3` ([ref](https://pandas.pydata.org/docs/reference/api/pandas.Series.set_axis.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_temp1 = pd.Series(['train', 'test'])\n",
    "s_temp2 = s_temp1.repeat([len(ps_y_log_train), len(ps_y_log_test)])\n",
    "s_temp3 = s_temp2.set_axis(range(len(ps_y_log_reduced)))\n",
    "\n",
    "df_y_combined = pd.DataFrame({\n",
    "    \n",
    "    'SalePrice': pd.concat([ps_y_log_train, ps_y_log_test]),\n",
    "    'tag':       s_temp3\n",
    "})\n",
    "\n",
    "# print(s_temp2.head(5))\n",
    "# print(\"\")\n",
    "# print(s_temp3.head(5))\n",
    "# print(\"\")\n",
    "# print(df_y_combined.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of SalePrice in both train and test data look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_combined['SalePrice'].hist(\n",
    "    \n",
    "    by      = df_y_combined['tag'],\n",
    "    figsize = (20,10),\n",
    "    xrot    = 15,\n",
    "    bins    = 50\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a4. Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable data is standardized so that each variable is represented at the same scale. Generally, there are two ways to scale variable data ([ref](https://www.analyticsvidhya.com/blog/2020/04/variable-scaling-machine-learning-normalization-standardization/)):\n",
    "\n",
    "* Normalization is a scaling technique in which values are translated and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n",
    "\n",
    "* Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)). This means that the mean of the variable becomes zero and the resultant distribution has a unit standard deviation.\n",
    "\n",
    "There is no rule to tell you what to choose when. You can always start by fitting your model to raw, normalized and standardized data, resp., and evaluate the three outcomes. In the example below, we will standardize the variable data so that each variable will have μ = 0 and σ = 1.\n",
    "\n",
    "Scaling of outcome variable is generally not required. Only when the outcome variable is not normally distributed, scaling will help to improve model performance.\n",
    "\n",
    "It is a good practice to fit the scaler on the training data and then use it to transform the testing data. This would avoid any data leakage during the model testing process. Therefore, we use scikit-learn's `fit()` and `transform()` functions in subsequent steps, even though scikit-learn also has a `fit_transform()` function that does both in one go. The difference between `fit()` and `transform()`:\n",
    "1. 'fit' applies a transformer, like scaling or encoder. The result is an updated 'machine'.\n",
    "2. 'transform' transforms input data to output data. The updated machine is used to convert raw material (input) to a product (output).\n",
    "\n",
    "The downside of `fit_transform()` is that in case we apply if before to the train/test split, we leak information from the test data into the training data ([ref](https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe)). If we apply it after the train/test split we introduce different means and standard deviations in both train and test data. Applying `Fit()` to the train data allows us to use the resulting mean and standard deviation to standardize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling object.\n",
    "scaler = StandardScaler()\n",
    " \n",
    "# Standardization of variables in training data.\n",
    "scaler_fitted_on_X_train = scaler.fit(df_X_train)\n",
    "\n",
    "# Key properties of scaler object.\n",
    "pd.DataFrame({'name': l_df_X_names_subset, 'mean': scaler_fitted_on_X_train.mean_, 'sd': scaler_fitted_on_X_train.scale_})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `scaler` object - that was 'fitted' on the variables of the training data - in our hands, we can apply it to transform the original variables in the training data as well as to transform the variables in the test data. This approach avoids any information leakage from the test data into the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_scaled = pd.DataFrame(\n",
    "    scaler_fitted_on_X_train.transform(df_X_train),\n",
    "    columns = l_df_X_names_subset\n",
    ")\n",
    "\n",
    "df_X_test_scaled  = pd.DataFrame(\n",
    "    scaler_fitted_on_X_train.transform(df_X_test),\n",
    "    columns = l_df_X_names_subset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(\n",
    "    \n",
    "#     data        = pd.melt(df_X_train_scaled),\n",
    "#     #data       = pd.melt(df_X_test_scaled),\n",
    "#     x           = \"value\",\n",
    "#     hue         = \"variable\",\n",
    "#     legend      = True\n",
    "# );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a5. Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed all preparations, we can train the linear regression model on the train data. It starts by defining `mo_lin_reg` as an empty linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mo_lin_reg = LinearRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What attributes are available in the 'empty' model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lin_reg.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill it by fitting the model on the train data. We update the object by fitting the model on the train data (input/output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lin_reg.fit(df_X_train_scaled, ps_y_log_train);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we use `__dict__` to see what attributes are available in the `mo_lin_reg` object. Now, we observe the availability of the coefficients (`coef_`) and the intercept (`intercept_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo_lin_reg.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a6. Interpret the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the larger the correlation with the `SalePrice` the larger the fitted coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intercept: {round(mo_lin_reg.intercept_):,}\\n\")\n",
    "\n",
    "print(\"Coefficients:\")\n",
    "\n",
    "pd.DataFrame({\n",
    "    'variable': l_df_X_names_subset,    \n",
    "    'coeff':   [str(round(x,3)) for x in mo_lin_reg.coef_],\n",
    "    'corr':    df_corr_table.query('name in @l_df_X_names_subset')['corr']\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a7. Make predictions based on estimated model and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model - present in `line_reg` - is used to make `SalePrice` predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_y_log_pred = mo_lin_reg.predict(df_X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a8. Evaluate estimated model based on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three primary metrics that can be used to evaluate regression models:\n",
    "\n",
    "* **Mean Absolute Error (MAE):** The easiest to understand. Represents average error.\n",
    "\n",
    "* **Mean Squared Error (MSE):** Similar to MAE but noise is exaggerated and larger errors result in higher “punishment”, as the error is squared. MSE is harder to interpret than MAE as it’s not in base units, however, it is generally more popular.\n",
    "\n",
    "* **Root Mean Squared Error (RMSE):** Most popular metric, similar to MSE, however, RMSE is the square root of the MSE making it more interpretable as it’s in the same unit as the outcome variable. This makes RMSE the recommended metric to interpret your linear regression model.\n",
    "\n",
    "Since we will evaluate these metrics more often, a function was defined, `f_evaluation_results()`, see 'i_general.py':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.exp(ps_y_log_pred), np.exp(ps_y_log_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_pred, ps_y_log_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Estimate a LASSO model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO (Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model ([ref](https://machinelearningmastery.com/lasso-regression-with-python/)). Recall that for regularized linear regression a cost function is added. In case of LASSO this is:\n",
    "\n",
    "$$ J(\\Theta) = MSE (\\Theta) + \\alpha\\sum\\limits_{i=1}^n \\mid{\\Theta_{i}}\\mid$$\n",
    "\n",
    "The larger the hyperparameter $\\alpha$ - sometimes referred to as $\\lambda$ - the larger the penalty and hence more coefficients will be set to zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b1. Define number of objects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the numerical variables in the data (`df_X`) you may also want to include categorical data to predict the `SalePrice`. To give an example, earlier, we observed that `Neighborhood` correlated well with `SalePrice`. This can be done by so-called 'One-Hot Encoding' ([ref1](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/), [ref2](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd)). In the example below we process the data to add the `Neighborhood` variable to the predictor data. One-hot encoding adds new variables to the data, one for each unique value and entering a '1' for observations where it had the concerned value and a '0' in all other cases.\n",
    "\n",
    "You can see how the `fit_transform()` function is also used here. As in case of scaling, we could perform 'fit' and 'transform' separately. To simplify we do them both in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define a one-hot encoder object.\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# The fit_transform() function produces a 'sparse matrix' object. To convert the data to\n",
    "# a dataframe we first need to convert it to a matrix.\n",
    "sm_neighborhoods = ohe.fit_transform(df_reduced[['Neighborhood']])\n",
    "m_neighborhoods  = sm_neighborhoods.toarray()\n",
    "\n",
    "# The one-hot encoder object 'ohe' has been updated by applying the fit_transform() function to it.\n",
    "# Now it has the 'categories_' attribute. Since it is an array in a list we take the first element.\n",
    "# Note, we convert the default floats to integers to save memory (more for demo purposes, since our\n",
    "# dataset is relatively small already).\n",
    "df_X_ohe = pd.DataFrame(data=m_neighborhoods, columns=ohe.categories_[0]).astype('int')\n",
    "\n",
    "# Comms to the user. The created data frame has as many variables as there are unique values in the\n",
    "# 'Neighborhood' variable in df_reduced and the same number of observations as df_reduced has.\n",
    "# No surprises.\n",
    "print(f\"Unique neighborhoods: {ohe.categories_[0]}\\n\")\n",
    "\n",
    "print(f\"Length of 'categories_' attribute: {len(ohe.categories_[0])}\")\n",
    "print(f\"Number of unique neighborhoods:    {len(df_reduced['Neighborhood'].unique())}\\n\")\n",
    "\n",
    "print(f\"Dimensions of created data frame:  {df_X_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two dataframes horizontally, i.e, 'axis' is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_combined = pd.concat([df_X, df_X_ohe], axis = 1)\n",
    "\n",
    "# Comms to the user. The created data frame 'df_X_combined' has as many observations as both 'X' and 'X_ohe' have,\n",
    "# and as many columns as the two have together. \n",
    "print(\"\\nThe sum of the number of columns in df_X and df_X_ohe must equal that in df_X_combined:\")\n",
    "print(f\"Number of variables in df_X:          {df_X.shape[1]}\")\n",
    "print(f\"Number of variables in df_X_ohe:      {df_X_ohe.shape[1]}\")\n",
    "print(f\"Number of variables in df_X_combined: {df_X_combined.shape[1]}\")\n",
    "\n",
    "print(\"\\nThe number of rows must all be the same:\")\n",
    "print(f\"Number of rows in df_X:              {df_X.shape[0]}\")\n",
    "print(f\"Number of rows in df_X_ohe:          {df_X_ohe.shape[0]}\")\n",
    "print(f\"Number of rows in df_X_combined:     {df_X_combined.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b2. Visualize predictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show a sample of the combined data frame to clarify how one-hot coding works and how the result was added to the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_combined.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b3. Split the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the predictor data using Scikit-Learn's `train_test_split()` ([*ref*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)), see `i_general.py` for more information on `f_train_test_split()`. We can follow two scenarios:\n",
    "\n",
    "Scenario A - Use the numerical variables only (df_X), so excluding any one-hot encoded categorical variables.\n",
    "\n",
    "Scenario B - Use the combined data (df_X_combined).\n",
    "\n",
    "Depending on what scenario you want to follow, add/remove the '#'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario A.\n",
    "#df_X_train, df_X_test, ps_y_log_train, ps_y_log_test = f_train_test_split(df_X, ps_y_log_reduced)\n",
    "\n",
    "# Scenario B.\n",
    "df_X_train, df_X_test, ps_y_log_train, ps_y_log_test = f_train_test_split(df_X_combined, ps_y_log_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b4. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we standardize `df_X_train` and `df_X_test` separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling object.\n",
    "scaler = StandardScaler()\n",
    " \n",
    "# Standardization of variables in train data.\n",
    "scaler_fitted_on_X_train = scaler.fit(df_X_train)\n",
    "\n",
    "# Key properties of scaler object for first 10 variables in X_combined.\n",
    "pd.DataFrame({'name': df_X_train.columns, 'mean': scaler_fitted_on_X_train.mean_, 'sd': scaler_fitted_on_X_train.scale_}).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_scaled = pd.DataFrame(\n",
    "    scaler_fitted_on_X_train.transform(df_X_train),\n",
    "    columns = df_X_train.columns\n",
    ")\n",
    "\n",
    "df_X_test_scaled  = pd.DataFrame(\n",
    "    scaler_fitted_on_X_train.transform(df_X_test),\n",
    "    columns = df_X_test.columns\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the scaled data. In the one-hot encoded neighborhood variables we observe that the 0's and 1's have been replaced by a negative and a positive number, resp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_scaled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(\n",
    "       \n",
    "#     data        = pd.melt(df_X_train_scaled[['Overall Qual', '1st Flr SF']]),\n",
    "#     x           = \"value\",\n",
    "#     hue         = \"variable\",\n",
    "#     legend      = True\n",
    "# );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b5. Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using Scikit Learn's `Lasso()` function to build a single model, we use `LassoCV()` to build a series of LASSO models. By default `LassoCV()` tries 100 different values for $\\alpha$, through the input parameter `n_alphas`. We make use of an example given in SciKit Learn's documentation providing a list of $\\alpha$'s ourselves ([ref](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Explainer - To explain the list comprehension used below:\n",
    "#np.arange(-3.5, -0.5, 0.1)\n",
    "#np.arange(-3.5+0, -0.5, 0.1)\n",
    "#[round(10**i,3) for i in np.arange(-3.5+0, -0.5, 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Define log of lower border of alphas range.\n",
    "#n_alphas_min = -3.5\n",
    "\n",
    "mo_lasso = LassoCV(\n",
    "    \n",
    "    # Number of folds.\n",
    "    cv           = 5,\n",
    "\n",
    "    # Fixing random_state ensures the results are reproducible.\n",
    "    random_state = 42,\n",
    "\n",
    "    # Use any CPU available.\n",
    "    #n_jobs       = -1,\n",
    "\n",
    "    # Max number of iterations.\n",
    "    max_iter     = 1000,\n",
    "\n",
    "    # We can enforce for which alphas a Lasso model is fitted.\n",
    "    # In case we do not provide a list, LassoCV() will select 100 values.\n",
    "    # In case you raise the '0' after to '+' to say '2.5' you select a smaller set of alphas that LassoCV can choose from.\n",
    "    # This results in larger 'optimal' alpha and we can investigate the effect in section b6. below. \n",
    "    #alphas       = [round(10**i) for i in np.arange(n_alphas_min+0, -0.5, 0.1)]\n",
    "\n",
    ").fit(\n",
    "    \n",
    "    df_X_train_scaled,\n",
    "    ps_y_log_train\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b6. Interpret the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the folds we plot the RMSE against the respective $\\alpha$'s we added as parameter to `LassoCV()`, see colored dotted lines in the figure below. We also add the mean of the folds, see black line. This plot allows us to choose the optimal $\\alpha$, i.e., the one that results in the lowest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 5)\n",
    "\n",
    "df_alpha = pd.DataFrame({\n",
    "    'alpha':     mo_lasso.alphas_,\n",
    "    'RMSE_mean': np.sqrt(mo_lasso.mse_path_.mean(axis=-1))\n",
    "})\n",
    "\n",
    "df_alpha.sort_values(by = 'alpha').iloc[20:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is selected based on the lowest RMSE. The alpha for that model can be obtained through the attribute `alpha_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "print(f\"Lowest RMSE found at alpha: {mo_lasso.alpha_:,.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to avoid division by zero while doing semilogx on the alphas.\n",
    "EPSILON = 0.000000001\n",
    "\n",
    "# Plot RMSE of 5 CV's.\n",
    "plt.semilogx(\n",
    "    \n",
    "    mo_lasso.alphas_ + EPSILON,\n",
    "    np.sqrt(mo_lasso.mse_path_), \":\"\n",
    ")\n",
    "\n",
    "# Plot mean RMSE of 5 CV's.\n",
    "plt.plot(\n",
    "    \n",
    "    df_alpha['alpha'] + EPSILON,\n",
    "    df_alpha['RMSE_mean'],\n",
    "\n",
    "    color     = \"k\",\n",
    "    label     = \"Average across the folds\",\n",
    "    linewidth = 2,\n",
    ")\n",
    "\n",
    "# Plot vertical dashed line at the alpha value that results in the lowest RMSE.\n",
    "# Note, the difference between '.alpha_' (below) and '.alphas_' (above).\n",
    "plt.axvline(\n",
    "    \n",
    "    mo_lasso.alpha_ + EPSILON,\n",
    "\n",
    "    linestyle = \"--\",\n",
    "    color     = \"k\",\n",
    "    label     = \"alpha: CV estimate\"\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Root mean square error\")\n",
    "plt.title(\"Root mean square error on each fold: coordinate descent\")\n",
    "plt.axis(\"tight\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `mo_lasso` object we can extract the intercept and coefficients of the best model. What explains the number of coefficients equal to zero? How can we increase the number of coefficients equal to zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"intercept: {mo_lasso.intercept_:,.2f}\")\n",
    "\n",
    "df_lasso_coefficients = pd.DataFrame(\n",
    "\n",
    "    {\n",
    "        'name':            df_X_train_scaled.columns,\n",
    "        'lasso coeff':     mo_lasso.coef_,\n",
    "        'lasso_coeff_abs': abs(mo_lasso.coef_)        \n",
    "    }\n",
    "\n",
    ").sort_values(\n",
    "\n",
    "    'lasso_coeff_abs',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "df_lasso_coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b7. Make predictions based on estimated model and test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mo_lasso` object holds the properties of the best model, i.e., the one resulting in the lowest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_y_log_pred = mo_lasso.predict(df_X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b8. Evaluate estimated model based on test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same three primary metrics are used to evaluate the best LASSO model. The RMSE is considerably lower, however, we require a lot more variables. Using $\\alpha$ we can reduce the number of included variables, but this goes at the 'expense' of a higher RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_test, ps_y_log_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Estimate a kNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we develop a kNN model to predict the `SalePrice` ([ref](https://realpython.com/knn-python/)). We define a KNeighborsRegressor object, called `knn_model`, that is further informed by fitting the training data. Contrary to (LASSO) regression, we keep this section on kNN simple and to the point; you got the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Define KNN object.\n",
    "mo_knn = KNeighborsRegressor(n_neighbors = 2)\n",
    "\n",
    "mo_knn.fit(df_X_train_scaled, ps_y_log_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained kNN model is used to predict `SalePrice` for the train and test data. We do this to investigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_train, mo_knn.predict(df_X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_test, mo_knn.predict(df_X_test_scaled))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For low values of `n_neighbors` the model is highly flexible and we are running the risk of over-fitting. Observing the RMSE value for the train and test set, we can conclude that we are indeed overfitting. We can make use of SciKit Learn's `GridSearchCV()` function to work through a series of hyperparameters, and determine for which hyperparameter we found the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"n_neighbors\": range(1, 50)}\n",
    "gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "gridsearch.fit(df_X_train_scaled, ps_y_log_train)\n",
    "\n",
    "# Comms to the user\n",
    "print(f\"We found the best model for {gridsearch.best_params_}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_train, gridsearch.predict(df_X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_test, gridsearch.predict(df_X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, no over-fitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 - Assess which model performs best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is discussed with each of the models. I leave making the overall assessment to you ;-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A - Use Pipelines to model Ames Housing data with LASSO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we repeat - more or less - what we did above, but now using pipelines to demonstrate their use. See also Python Explainer 'pipelines' in the syllabus. Besides the functions `Pipeline()` or `make_pipeline()` we make use of the `ColumnTransformer()` function to process numerical and categorical variables differently. We start out by defining separate pipelines for numerical and categorical variables. Here, we use the `Pipeline()` function, instead of the `make_pipeline()` function to make it easier to reference to individual transformers later on. Imputation is performed by SciKit Learn's `SimpleImputer()` function ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for numerical variables.\n",
    "pl_Num = Pipeline([\n",
    "\n",
    "        ( \"impute\", SimpleImputer(missing_values = np.nan, strategy = \"median\") ),\n",
    "\n",
    "        ( \"scale\",  StandardScaler() )\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical variables.\n",
    "pl_Cat = Pipeline([\n",
    "\n",
    "        ( \"impute\", SimpleImputer(missing_values = np.nan, strategy = \"most_frequent\") ),\n",
    "\n",
    "        ( \"onehot\", OneHotEncoder() )\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `transformers` in the function `ColumnTransformer()` receives a list of tuples each containing: (1) transformer name, (2) transformer, and (3) variable name(s). Each tuple specifies how the specified variables in the concerned tuple are transformed ([ref](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)).\n",
    "\n",
    "Note, `remainder = 'drop'` tells the transformer to drop the variables not mentioned in the tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define transformer object.\n",
    "pl_ColumnTransformer = ColumnTransformer(\n",
    "    \n",
    "    transformers = [\n",
    "        \n",
    "        # Tuples containing transformer name, transformer, and variable names for each transformation to take place.\n",
    "        ('num', pl_Num, l_df_X_names),\n",
    "\n",
    "        # As we pull the data through a pipeline, it is easier to add more categorical variables.\n",
    "        ('cat', pl_Cat, ['Neighborhood'] + ['Pool QC'])\n",
    "    ],\n",
    "    \n",
    "    remainder = 'drop',\n",
    "    verbose   = True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with scaling and one-hot encoding we use the `fit_transform()` function to pull a data frame through the pipeline. While with scaling we perform `fit()` and `transform()` separately, to apply the scaling based on the train set to the test set, with one-hot encoding we perform both steps in one go by using `fit_transform()`. The latter approach we apply to the original data, `df_orig`, resulting in `m_X_transformed`.\n",
    "\n",
    "Do the number of columns in `m_X_transformed` correspond to what we expect?\n",
    "\n",
    "Why are we not able to do the calculation for 'Pool QC' in the same notation as for 'Neighborhoord'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_transformed = pl_ColumnTransformer.fit_transform(df_orig)\n",
    "\n",
    "print('')\n",
    "print(f\"Number of columns in the resulting array:         {m_X_transformed.shape[1]}\")\n",
    "print(f\"Number of numerical variables (excl. 'SalePrice'): {len(l_df_X_names)}\")\n",
    "print(f\"Number of unique values in 'Neighborhood':        {len(df_orig['Neighborhood'].value_counts())}\")\n",
    "print(f\"Number of unique values in 'Pool QC':             {len(df_orig['Pool QC'].value_counts())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next on our list of activities is to create a list of variable names, so we can convert the array `m_X_transformed` to a data frame and assign the corresponding variable names. For the numerical part this is easy, as the numerical variable names are stored in `l_df_X_names`. \n",
    "\n",
    "For the one-hot encoded variables - `Neighborhood` and `Pool QC` - this is a bit trickier. The object `pl_ColumnTransformer` contains the attribute `named_transformers_`. This has two elements, 'num' and 'cat', i.e., the names we gave to the respective transformers. We see the benefit of `Pipeline()` over `make_pipeline()`, since we can make use of the names that we gave to each pipeline. With `make_pipeline()` we do not (have to) give names to the individual transformers, Python creates them for us. However, this means that it is more cumbersome to refer to individual transformers, if needed at later stage, as we see here. See also Python Explainer 'pipeline' in the syllabus.\n",
    "\n",
    "We assign the variable names derived from `pl_ColumnTransformer` to object `v_df_cat_transformed_names`, and we observe that they match what we derived above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_cat_transformed_names = pl_ColumnTransformer.named_transformers_['cat']['onehot'].get_feature_names_out(['neighborhood', 'pool_qc'])\n",
    "\n",
    "print(v_df_cat_transformed_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue and append the numeric variable names and those that follow from the two categorical variables, `Neighbordhood` and `Pool QC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_X_transformed_names = np.append(l_df_X_names, v_df_cat_transformed_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do our checks and balances to confirm the dimensions of our data is mathing our expectations, see below. The transformed data matrix `m_X_transformed` consists of as many columns as there are elements in `v_df_X_transformed_names` that we created from the numerical variables in `df_X` and the unique values in `Neighborhood` and `Pool QC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of columns in the resulting array: {m_X_transformed.shape[1]}\")\n",
    "print(f\"Length of 'v_df_X_transformed_names':     {len(v_df_X_transformed_names)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to construct data frame `df_X_transformed` that follows from the ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 2D array to a data frame:\n",
    "df_X_transformed = pd.DataFrame(m_X_transformed, columns = v_df_X_transformed_names)\n",
    "\n",
    "df_X_transformed.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the predictor data using Scikit-Learn's `train_test_split()` ([*ref*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_X_test, ps_y_log_train, ps_y_log_test = f_train_test_split(df_X_transformed, ps_y_log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using Scikit Learn's `Lasso()` function to build a single model, we use `LassoCV()` to build a series of LASSO models. By default `LassoCV()` tries 100 different values for $\\alpha$, through the input parameter `n_alphas`. We make use of an example given in SciKit Learn's documentation providing a list of $\\alpha$'s ourselves ([ref](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log of lower border of alphas range.\n",
    "#n_alphas_min = 2\n",
    "\n",
    "mo_lasso = LassoCV(\n",
    "    \n",
    "    # Number of folds.\n",
    "    cv           = 5,\n",
    "\n",
    "    # Fixing random_state ensures the results are reproducible.\n",
    "    random_state = 42,\n",
    "\n",
    "    # Use any CPU available.\n",
    "    #n_jobs       = -1,\n",
    "\n",
    "    # Max number of iterations.\n",
    "    max_iter     = 100000,\n",
    "\n",
    "    # We can enforce for which alphas a Lasso model is fitted.\n",
    "    # In case we do not provide a list, LassoCV() will select 100 values.\n",
    "    #alphas       = [round(10**i) for i in np.arange(n_alphas_min, n_alphas_min+3, 0.2)]\n",
    "\n",
    ").fit(\n",
    "    \n",
    "    df_X_train,\n",
    "    ps_y_log_train\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `mo_lasso` object we can extract the intercept and coefficients of the best model. What explains the number of coefficients equal to zero? How can we increase the number of coefficients equal to zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"intercept: {mo_lasso.intercept_:,.0f}\")\n",
    "\n",
    "pd.DataFrame(\n",
    "\n",
    "    {\n",
    "        'coef':     mo_lasso.coef_,\n",
    "        'coef_abs': abs(mo_lasso.coef_),\n",
    "        'variable':  df_X_train.columns\n",
    "    }\n",
    "\n",
    ").sort_values(\n",
    "\n",
    "    'coef_abs',\n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is selected based on the lowest RMSE. The alpha for that model can be obtained through the attribute `alpha_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Lowest RMSE found at alpha: {mo_lasso.alpha_:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mo_lasso` object holds the properties of the best model, i.e., the one resulting in the lowest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_y_log_pred = mo_lasso.predict(df_X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same three primary metrics are used to evaluate the best LASSO model. The RMSE is considerably lower than when we limited the predictor data to numerical variables only, see above. We observe that by adding `Neighborhood` to the model it can explain a larger part of the variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_log_test, ps_y_log_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Appendix B - Determine number of principle components to explain 90% of variance in the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we determine the number of principle components (PC) to explain 90% of the variance in the data using a pipeline ([ref](https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60)), see also 'ML Explainer' 'pca'. So, we need access to the `explained_variance_ratio_` attribute of a PCA object. As far as I know, this can only be done outside the pipeline. In case we are only interested in the principle components themselves, we can include `PCA(n_components = ...)` in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_impute_scale_numerical = make_pipeline(\n",
    "    \n",
    "    SimpleImputer(missing_values = np.nan, strategy = \"median\"),\n",
    "\n",
    "    StandardScaler()\n",
    "\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is applied to the numerical variables in the original data (`df_orig`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_X_transformed = pl_impute_scale_numerical.fit_transform(df_orig[l_df_X_names])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a PCA object `pca_` anticipating that 25 principle components will cover at least 90% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define PCA object.\n",
    "pca_ = PCA(n_components=25)\n",
    "\n",
    "# Matrix containing the principle components.\n",
    "m_pc = pca_.fit_transform(m_X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `explained_variance_ratio_` holds the additional variance that is explained by adding another principle component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_pca_ames = pca_.explained_variance_ratio_\n",
    "v_pca_ames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a list comprehension, we demonstrate that 23 PC's are needed to explain at least 90% of the total variance in the data. In other words the 23 PC's contain 90% of the information present in the 38 variables. To show the outcome of `np.cumsum(v_pca_ames)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(l_df_X_names))\n",
    "\n",
    "np.cumsum(v_pca_ames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[i,j] for i,j in enumerate(np.cumsum(v_pca_ames))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the following in one table to compare the order of the numerical variables in the data, see table below:\n",
    "\n",
    "1. **Pearson Correlation coefficients** of the numerical variables with `SalePrice`.\n",
    "\n",
    "2. **LASSO coefficients** fitting the numerical variables to a LASSO model predicting `SalePrice`.\n",
    "\n",
    "3. **PCA loadings** of first the principle component ('PC1'). Note, this is independent of `SalePrice`.\n",
    "\n",
    "Two housekeeping remarks:\n",
    "1. We make use of `reset_index(drop=True)` to concatenate the data frames as there are offered. Without it, the data frames would be joined using the original index and all variable names would end up in the same row driven by the index of the first data frame, the correlation coefficients in this case.\n",
    "\n",
    "2. In 'Step 3 - Split the data' in section 'Estimate a LASSO model' two scenario's can be chosen (A and B). Subsequently, in step 6 of the same section, `df_lasso_coefficients` is calculated. To allow for a proper comparison of the correlation coefficients, the LASSO coefficients, and the PCA loadings, please ensure you ran scenario A and steps 3-6 accordingly.\n",
    "\n",
    "The table below allows us to investigate the numerical variable order in each of the three analysis. Comparing the Pearson correlation coefficients and the LASSO coefficients shows that the first two variables occur at the top of each list. We also expect variables that have a high correlation with the `SalePrice` to also end up high in the LASSO coefficient table. *Question: Why?* However, the equality does not continue all the way down. `Garage Area` is high in the list of correlation coefficients, however, it is somewhere in the middle in the list of LASSO coefficients. *Why is this the case?* Since LASSO wants to include as few variables as possible (regularization, remember $\\alpha$) it will choose one of the two. Both are highly correlated (not shown in the table), so the information is sufficiently captured in one of the two.  We observe the same for `Gr Liv Area` and `1st Flr SF`. The table suggests that the variable with the higher correlation with `SalePrice` is chosen for LASSO and the other one is *punished* by giving it a lower LASSO coefficient. So, correlations between variables causes the order in the two lists to differ.\n",
    "\n",
    "We observe no similarity between the order in variables between the loadings in the first principle component (PC1) on the one hand and the correlations and LASSO coefficients on the other hand. Possibly, this is explained by PCA only focussing on the predictor data (X), where correlations and LASSO depend on the relation between the predictor data (X) and `SalePrice` (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_lasso_coefficients.shape[0] != 38:\n",
    "    print(\"Before proceeding, run Scenario A ('numerical only') in Step 3 of section 'Estimate a LASSO model', and run steps 3-6 above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "        \n",
    "    [   # Correlation coefficients. Note, we remove the first row containing correlation of SalePrice with itself.\n",
    "        df_corr_table.tail(-1).reset_index(drop=True),\n",
    "\n",
    "        #LASSO coefficients.\n",
    "        df_lasso_coefficients.reset_index(drop=True),\n",
    "          \n",
    "        # PCA Loadings.  \n",
    "        pd.DataFrame({\n",
    "            \n",
    "            'name': l_df_X_names,\n",
    "            'pc1_loading': [\"{:.2f}\".format(x) for x in pca_.components_[1]],\n",
    "            'pc1_loading_abs': [\"{:.2f}\".format(abs(x)) for x in pca_.components_[1]]\n",
    "\n",
    "        }).sort_values(\n",
    "            \n",
    "            by = 'pc1_loading_abs',\n",
    "            ascending = False\n",
    "            \n",
    "        ).reset_index(drop=True)\n",
    "    ],\n",
    "    \n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 - Interpretable Machine Learning - Using SHAP values to explain contribution of variables to prediction of Sale Price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some suggestions to enter in chatGPT:\n",
    "* How to import random forrest regression model in python?\n",
    "* What hyperparameters do I have access to in this model?\n",
    "* Can you suggest a dictionary with some common ranges to use with these hyperparameters?\n",
    "* How to use this model in conjunction with gridsearchcv?\n",
    "\n",
    "Of course, these questions are already quite specific and when you start your questions might be more generic, like \"How do I do check the performance on a range of hyperparameters\". The examples above show that also as you develop your knowledge, ChatGPT remains a very good source for suggesting snippets of code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A - Construct a data frame holding the imputed numerical data of the Ames Housing data set. Optionally, as a challenge, also include the one hot encoded neighborhoods. Perform a train/test split on the data frame you constructed. Since, the SHAP calculation are computer intensive, take the first 500 observations from the resulting training set (call it, `df_X_fraction`) and take the first 500 elements of the outcome variable from the resulting training set (call it, `ps_y_fraction`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to obtain the two objects is to run scenario B in Exercise 5.3b\n",
    "\n",
    "# We take a fraction from the data to speed up the exercise. SHAP analysis are computer intensive.\n",
    "df_X_fraction = df_X_train.iloc[0:500]\n",
    "ps_y_fraction = ps_y_log_train[0:500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B - Copy/paste the content from the cell below to your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Hyperparameter grid:\n",
    "dc_hyperparameter_ranges = {\n",
    "\n",
    "    'bootstrap': [True,False], # Do we bootstrap samples, or not.\n",
    "    'max_depth': [20],         # Maximum depth of each tree\n",
    "    'min_samples_leaf': [4],   # Minimum number of samples required to be at a leaf node\n",
    "    'min_samples_split': [4],  # Minimum number of samples required to split an internal node\n",
    "    'n_estimators': [1000],    # Number of trees\n",
    "    'max_variables': ['auto'],  # Number of variables to consider at each split\n",
    "    'random_state': [42]       # Random state for reproducibility\n",
    "}\n",
    "\n",
    "# Perform a gridsearch on the random forest model:\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator  = RandomForestRegressor(),\n",
    "    param_grid = dc_hyperparameter_ranges,\n",
    "    scoring    = 'neg_mean_squared_error',\n",
    "    cv         = 5\n",
    ")\n",
    "\n",
    "# Use subset of training data to do a gridsearch on the random forest model:\n",
    "gridsearch.fit(df_X_fraction, ps_y_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C - Show the value of the `best_params` attribute of the `gridsearch` object. What do the attributes `best_params_` and `best_estimator_` refer to? Assign the value of the `best_estimator_` attribute to a new object called, `best_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from the set of hyperparameters.\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the best model. So, we do not need to rerun the model with the best parameters.\n",
    "best_model = gridsearch.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two cell below are extra (no exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_evaluation_results(ps_y_fraction, gridsearch.predict(df_X_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.scatter(ps_y_fraction, gridsearch.predict(df_X_fraction))\n",
    "plt.plot([9, 14], [9, 14], color='r', linestyle='-', linewidth=2)\n",
    "plt.xlabel('Actual Test',size=20)\n",
    "plt.ylabel('Predicted Test',size=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise D - Copy/paste the content from the cell below to your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Create SHAP object.\n",
    "explainer = shap.Explainer(best_model)\n",
    "\n",
    "# Create SHAP values.\n",
    "shap_values = explainer.shap_values(df_X_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise E - Waterfall Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the waterfall function to visualise the SHAP values of one observation. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Define an object to which you assign the index of the data point you want to explain the prediction for. Assign the value to your object such that you can explain the prediction for the first observation in the data.\n",
    "\n",
    "2 - Replace '...' by the object name you defined above.\n",
    "\n",
    "3 - What is the value for explainer.expected_value[0]?\n",
    "\n",
    "4 - Run the cell.\n",
    "\n",
    "5 - What do you conclude from the resulting figure? Use: (1) the answer from question 3 and (2) the prediction for the first observation in the data.\n",
    "\n",
    "For reference see also [API Reference of SHAP module](https://shap.readthedocs.io/en/latest/generated/shap.plots.waterfall.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of data point you want to explain the prediction for.\n",
    "index = 1\n",
    "\n",
    "# Plot waterfall\n",
    "shap.plots.waterfall(\n",
    "    \n",
    "    shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values[index],          # Subset of shap values.\n",
    "        data          = df_X_fraction.iloc[index],   # Subset of training data.\n",
    "        feature_names = df_X_fraction.columns        # variable names.\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - index = 1\n",
    "\n",
    "# 2 - index\n",
    "\n",
    "# 3 - It is the mean prediction for the entire training data. The answer should be a number; in my case it is 12.01.\n",
    "# Though in individual cases the number may differ because we sampled the data differently.\n",
    "\n",
    "# 5 - There will be a unique waterfall plot for every observation in our dataset. They can all be interpreted in\n",
    "# the same way as above. In each case, the SHAP values tell us how the variables have contributed to the prediction\n",
    "# when compared to the mean prediction. Large positive/negative values indicate that the variable had a significant\n",
    "# impact on the model’s prediction. The prediction of 12.27 (in my case) can be constructed from the base value of\n",
    "# 12.01 (mean prediction) and the contributions of the individual variables in the data, e.g., the value of 0.6416\n",
    "# for Overal Qual (in my case) add almost 0.26 to the prediction for the log of the sales price."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise F - Force Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualise these is using a force plot. You can think of this as a condensed waterfall plot. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - The force plot is a different representation of the waterfall plot. Apply the questions from exercise 1 to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of data point you want to explain the prediction for. Write the answer to question a, below.\n",
    "index = 1\n",
    "\n",
    "# Plot Force Plot.\n",
    "shap.plots.force(\n",
    "\n",
    "    base_value    = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "    shap_values   = shap_values[index],          # SHAP values.\n",
    "    variables      = df_X_fraction.iloc[index],   # Training data.\n",
    "    feature_names = df_X_fraction.columns        # variable names.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# See Exercise E."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise G - Stacked Force Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waterfall and force plots are great for interpreting individual predictions. To understand how our model makes predictions in general we need to aggregate the SHAP values. One way to do this is by using a stacked-force plot. We can combine multiple force plots together to create a stacked force plot. Here we pass all SHAP values in the force plot function; though we can limit it. Each individual force plot is now vertical and stacked side by side. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell and point out the value for explainer.expected_value[0].\n",
    "\n",
    "2 - Set the dropdown at the top of the figure and to the left of the figure to 'Overall Qual'. What do you conclude from the resulting curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked force plot.\n",
    "shap.plots.force(\n",
    "    \n",
    "        base_value    = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        shap_values   = shap_values,                 # SHAP values.\n",
    "        variables      = df_X_fraction,               # Training data.\n",
    "        feature_names = df_X_fraction.columns        # variable names.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - The mean prediction (in my case 12.01) can be seen where the blue polygon hits the y-axis.\n",
    "\n",
    "# 2 - We observe that as 'Overall Qual' increases, the SHAP value for Overall Qual increases.\n",
    "# In other words, houses with higher overall quality tend to have higher sales prices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise H - Mean SHAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next plot will tell us which variables are most important. For each variable, we calculate the mean SHAP value across all observations. Specifically, we take the mean of the absolute values as we do not want positive and negative values to offset each other. There is one bar for each variable. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell. What do you conclude from the resulting chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean SHAP.\n",
    "shap.plots.bar(\n",
    "\n",
    "    shap_values = shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values,                 # Subset of shap values.\n",
    "        data          = df_X_fraction,               # Subset of training data.\n",
    "        feature_names = df_X_fraction.columns        # variable names.\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - Variables that have made large positive/negative contributions will have a large mean SHAP value.\n",
    "# In other words, these are the variables that have had a significant impact on the model’s predictions.\n",
    "# In this sense, this plot can be used in the same way as a variable importance plot.\n",
    "# Overall Qual is the biggest explainer of the sale price, by far."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise I - Beeswarm Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the single most useful plot. The beeswarm visualises all of the SHAP values. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell. What do you conclude from the resulting chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot beeswarm plot.\n",
    "shap.plots.beeswarm(\n",
    "    \n",
    "    shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values,                 # SHAP values.\n",
    "        data          = df_X_fraction,               # Training data.\n",
    "        feature_names = df_X_fraction.columns        # Variable names.\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - On the y-axis, the values are grouped by variable. For each group, the colour of the points is\n",
    "# determined by the variable value (i.e. higher variable values are redder).\n",
    "# We can also start to understand the nature of these relationships. For Overall Quality, notice how as\n",
    "# the variable value increases the SHAP values increase. We saw a similar relationship in the stacked\n",
    "# force plot. It tells us that larger values for Overall Quality will lead to a higher predicted Sale Price.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebb0a02d86bd6cc81bd76bc6c4cba297e0e4bde90b1df44b0c10ac2ad7a9009a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
