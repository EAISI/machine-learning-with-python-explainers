{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Step-by-step - Exercise 7\n",
    "\n",
    "Pieter Overdevest  \n",
    "2024-02-09\n",
    "\n",
    "For suggestions/questions regarding this notebook, please contact\n",
    "[Pieter Overdevest](https://www.linkedin.com/in/pieteroverdevest/)\n",
    "(pieter@innovatewithdata.nl).\n",
    "\n",
    "### How to work with this Jupyter Notebook yourself?\n",
    "\n",
    "- Get a copy of the repository ('repo') [machine-learning-with-python-explainers](https://github.com/EAISI/machine-learning-with-python-explainers) from EAISI's GitHub site. This can be done by either cloning the repo or simply downloading the zip-file. Both options are explained in this Youtube video by [Coderama](https://www.youtube.com/watch?v=EhxPBMQFCaI).\n",
    "\n",
    "- Copy the folders 'ames_housing_pieter\\' and 'utils_pieter\\' folder to your own project folder.\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages and assign to a shorter alias.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pieter's utils package.\n",
    "import utils_pieter as up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 - Interpretable Machine Learning - Using SHAP values to explain contribution of variables to prediction of Sale Price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some suggestions to enter in chatGPT:\n",
    "* How to import random forrest regression model in python?\n",
    "* What hyperparameters do I have access to in this model?\n",
    "* Can you suggest a dictionary with some common ranges to use with these hyperparameters?\n",
    "* How to use this model in conjunction with gridsearchcv?\n",
    "\n",
    "Of course, these questions are already quite specific and when you start your questions might be more generic, like \"How do I do check the performance on a range of hyperparameters\". The examples above show that also as you develop your knowledge, ChatGPT remains a very good source for suggesting snippets of code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A - Construct a data frame holding the imputed numerical data of the Ames Housing data set. Optionally, as a challenge, also include the one hot encoded neighborhoods. Perform a train/test split on the data frame you constructed. Since, the SHAP calculation are computer intensive, take the first 500 observations from the resulting training set (call it, `df_X_fraction`) and take the first 500 elements of the outcome variable from the resulting training set (call it, `ps_y_fraction`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to obtain the two objects is to run scenario B in Exercise 5.3b\n",
    "\n",
    "# We take a fraction from the data to speed up the exercise. SHAP analysis are computer intensive.\n",
    "df_X_fraction = df_X_train.iloc[0:500]\n",
    "ps_y_fraction = ps_y_log_train[0:500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B - Copy/paste the content from the cell below to your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Hyperparameter grid:\n",
    "dc_hyperparameter_ranges = {\n",
    "\n",
    "    'bootstrap': [True,False], # Do we bootstrap samples, or not.\n",
    "    'max_depth': [20],         # Maximum depth of each tree\n",
    "    'min_samples_leaf': [4],   # Minimum number of samples required to be at a leaf node\n",
    "    'min_samples_split': [4],  # Minimum number of samples required to split an internal node\n",
    "    'n_estimators': [1000],    # Number of trees\n",
    "    'max_variables': ['auto'],  # Number of variables to consider at each split\n",
    "    'random_state': [42]       # Random state for reproducibility\n",
    "}\n",
    "\n",
    "# Perform a gridsearch on the random forest model:\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator  = RandomForestRegressor(),\n",
    "    param_grid = dc_hyperparameter_ranges,\n",
    "    scoring    = 'neg_mean_squared_error',\n",
    "    cv         = 5\n",
    ")\n",
    "\n",
    "# Use subset of training data to do a gridsearch on the random forest model:\n",
    "gridsearch.fit(df_X_fraction, ps_y_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C - Show the value of the `best_params` attribute of the `gridsearch` object. What do the attributes `best_params_` and `best_estimator_` refer to? Assign the value of the `best_estimator_` attribute to a new object called, `best_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from the set of hyperparameters.\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the best model. So, we do not need to rerun the model with the best parameters.\n",
    "best_model = gridsearch.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two cell below are extra (no exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up.f_evaluate_results(\n",
    "    ps_y_true = ps_y_fraction,\n",
    "    ps_y_pred = gridsearch.predict(df_X_fraction)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.scatter(ps_y_fraction, gridsearch.predict(df_X_fraction))\n",
    "plt.plot([9, 14], [9, 14], color='r', linestyle='-', linewidth=2)\n",
    "plt.xlabel('Actual Test',size=20)\n",
    "plt.ylabel('Predicted Test',size=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise D - Copy/paste the content from the cell below to your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Create SHAP object.\n",
    "explainer = shap.Explainer(best_model)\n",
    "\n",
    "# Create SHAP values.\n",
    "shap_values = explainer.shap_values(df_X_fraction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise E - Waterfall Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the waterfall function to visualise the SHAP values of one observation. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Define an object to which you assign the index of the data point you want to explain the prediction for. Assign the value to your object such that you can explain the prediction for the first observation in the data.\n",
    "\n",
    "2 - Replace '...' by the object name you defined above.\n",
    "\n",
    "3 - What is the value for explainer.expected_value[0]?\n",
    "\n",
    "4 - Run the cell.\n",
    "\n",
    "5 - What do you conclude from the resulting figure? Use: (1) the answer from question 3 and (2) the prediction for the first observation in the data.\n",
    "\n",
    "For reference see also [API Reference of SHAP module](https://shap.readthedocs.io/en/latest/generated/shap.plots.waterfall.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of data point you want to explain the prediction for.\n",
    "index = 1\n",
    "\n",
    "# Plot waterfall\n",
    "shap.plots.waterfall(\n",
    "    \n",
    "    shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values[index],          # Subset of shap values.\n",
    "        data          = df_X_fraction.iloc[index],   # Subset of training data.\n",
    "        feature_names = df_X_fraction.columns        # variable names.\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - index = 1\n",
    "\n",
    "# 2 - index\n",
    "\n",
    "# 3 - It is the mean prediction for the entire training data. The answer should be a number; in my case it is 12.01.\n",
    "# Though in individual cases the number may differ because we sampled the data differently.\n",
    "\n",
    "# 5 - There will be a unique waterfall plot for every observation in our dataset. They can all be interpreted in\n",
    "# the same way as above. In each case, the SHAP values tell us how the variables have contributed to the prediction\n",
    "# when compared to the mean prediction. Large positive/negative values indicate that the variable had a significant\n",
    "# impact on the model’s prediction. The prediction of 12.27 (in my case) can be constructed from the base value of\n",
    "# 12.01 (mean prediction) and the contributions of the individual variables in the data, e.g., the value of 0.6416\n",
    "# for Overal Qual (in my case) add almost 0.26 to the prediction for the log of the sales price."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise F - Force Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualise these is using a force plot. You can think of this as a condensed waterfall plot. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - The force plot is a different representation of the waterfall plot. Apply the questions from exercise 1 to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index of data point you want to explain the prediction for. Write the answer to question a, below.\n",
    "index = 1\n",
    "\n",
    "# Plot Force Plot.\n",
    "shap.plots.force(\n",
    "\n",
    "    base_value    = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "    shap_values   = shap_values[index],          # SHAP values.\n",
    "    variables      = df_X_fraction.iloc[index],   # Training data.\n",
    "    feature_names = df_X_fraction.columns        # variable names.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# See Exercise E."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise G - Stacked Force Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waterfall and force plots are great for interpreting individual predictions. To understand how our model makes predictions in general we need to aggregate the SHAP values. One way to do this is by using a stacked-force plot. We can combine multiple force plots together to create a stacked force plot. Here we pass all SHAP values in the force plot function; though we can limit it. Each individual force plot is now vertical and stacked side by side. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell and point out the value for explainer.expected_value[0].\n",
    "\n",
    "2 - Set the dropdown at the top of the figure and to the left of the figure to 'Overall Qual'. What do you conclude from the resulting curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked force plot.\n",
    "shap.plots.force(\n",
    "    \n",
    "        base_value    = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        shap_values   = shap_values,                 # SHAP values.\n",
    "        variables      = df_X_fraction,               # Training data.\n",
    "        feature_names = df_X_fraction.columns        # variable names.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - The mean prediction (in my case 12.01) can be seen where the blue polygon hits the y-axis.\n",
    "\n",
    "# 2 - We observe that as 'Overall Qual' increases, the SHAP value for Overall Qual increases.\n",
    "# In other words, houses with higher 'Overall qual' tend to have higher sales prices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise H - Mean SHAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next plot will tell us which variables are most important. For each variable, we calculate the mean SHAP value across all observations. Specifically, we take the mean of the absolute values as we do not want positive and negative values to offset each other. There is one bar for each variable. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell. What do you conclude from the resulting chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean SHAP.\n",
    "shap.plots.bar(\n",
    "\n",
    "    shap_values = shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values,                 # Subset of shap values.\n",
    "        data          = df_X_fraction,               # Subset of training data.\n",
    "        feature_names = df_X_fraction.columns        # variable names.\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - Variables that have made large positive/negative contributions will have a large mean SHAP value.\n",
    "# In other words, these are the variables that have had a significant impact on the model’s predictions.\n",
    "# In this sense, this plot can be used in the same way as a variable importance plot.\n",
    "# Overall Qual is the biggest explainer of the sale price, by far."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise I - Beeswarm Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the single most useful plot. The beeswarm visualises all of the SHAP values. Copy/paste the content from the cell below to your notebook. The questions refer to this code cell and to the resulting plot.\n",
    "\n",
    "1 - Run the cell. What do you conclude from the resulting chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot beeswarm plot.\n",
    "shap.plots.beeswarm(\n",
    "    \n",
    "    shap.Explanation(\n",
    "        base_values   = explainer.expected_value[0], # Mean prediction for the entire training data.\n",
    "        values        = shap_values,                 # SHAP values.\n",
    "        data          = df_X_fraction,               # Training data.\n",
    "        feature_names = df_X_fraction.columns        # Variable names.\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS\n",
    "\n",
    "# 1 - On the y-axis, the values are grouped by variable. For each group, the colour of the points is\n",
    "# determined by the variable value (i.e. higher variable values are redder).\n",
    "# We can also start to understand the nature of these relationships. For 'Overall Qual', notice how as\n",
    "# the variable value increases the SHAP values increase. We saw a similar relationship in the stacked\n",
    "# force plot. It tells us that larger values for 'Overall Qual' will lead to a higher predicted Sale Price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebb0a02d86bd6cc81bd76bc6c4cba297e0e4bde90b1df44b0c10ac2ad7a9009a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
